2025-07-17 00:38:14,687 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 68, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 335, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 376, in chat_answer
    async for info, answer in self.astream(question, chat_chain, chain_config, document_variable_names, **kwargs):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 635, in astream
    async for chunk in chat_chain.astream(chain_config):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3465, in astream
    async for chunk in self.atransform(input_aiter(), config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 647, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 636, in _atransform
    yield await first_map_chunk_task
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3963, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3949, in _atransform
    chunk = AddableDict({step_name: task.result()})
                                    ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3932, in get_next_chunk
    return await py_anext(generator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 95, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2282, in _atransform_stream_with_config
    final_input: Optional[Input] = await py_anext(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1489, in atransform
    async for output in self.astream(final, config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 598, in astream
    async for chunk in self._astream(
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 2698, in _astream
    async for chunk in super()._astream(*args, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1275, in _astream
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2454, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1784, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1584, in request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-2.5-pro-exp-03-25 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]
-chat_qa_chain_self_answer
2025-07-18 22:17:43,358 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 67, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 629, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 639, in chat_answer
    chat_chain = self.create_chat_chain(document_variable_names=document_variable_names, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 572, in create_chat_chain
    tool_chain = self.create_tool_chain(kwargs["tools"])
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 493, in create_tool_chain
    llm_with_tools = self.llm.bind_tools(tools)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1652, in bind_tools
    convert_to_openai_tool(tool, strict=strict) for tool in tools
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\function_calling.py", line 586, in convert_to_openai_tool
    oai_function = convert_to_openai_function(tool, strict=strict)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\function_calling.py", line 488, in convert_to_openai_function
    raise ValueError(msg)
ValueError: Unsupported function

AMAP

Functions must be passed in as Dict, pydantic.BaseModel, or Callable. If they're a dict they must either be in OpenAI function format or valid JSON schema with top-level 'title' and 'description' keys.
-chat_qa_chain_self_answer
2025-07-18 22:20:22,798 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 67, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 629, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 674, in chat_answer
    async for info, answer in self.astream(question, chat_chain,  chain_config, document_variable_names,
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 690, in astream
    async for chunk in chat_chain.astream(chain_config):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3465, in astream
    async for chunk in self.atransform(input_aiter(), config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 647, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2282, in _atransform_stream_with_config
    final_input: Optional[Input] = await py_anext(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5660, in atransform
    async for item in self.bound.atransform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5660, in atransform
    async for item in self.bound.atransform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 647, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 627, in _atransform
    raise ValueError(msg)  # noqa: TRY004
    ^^^^^^^^^^^^^^^^^^^^^
ValueError: The input to RunnablePassthrough.assign() must be a dict.
-chat_qa_chain_self_answer
2025-07-20 17:42:51,616 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 72, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 642, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 687, in chat_answer
    async for info, answer in self.astream(question, chat_chain,  chain_config, document_variable_names,
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 704, in astream
    async for chunk in chat_chain.astream(chain_config):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3465, in astream
    async for chunk in self.atransform(input_aiter(), config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 647, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 636, in _atransform
    yield await first_map_chunk_task
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3963, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3949, in _atransform
    chunk = AddableDict({step_name: task.result()})
                                    ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3932, in get_next_chunk
    return await py_anext(generator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 95, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2282, in _atransform_stream_with_config
    final_input: Optional[Input] = await py_anext(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1471, in atransform
    async for ichunk in input:
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1471, in atransform
    async for ichunk in input:
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5660, in atransform
    async for item in self.bound.atransform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 647, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 636, in _atransform
    yield await first_map_chunk_task
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3963, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3949, in _atransform
    chunk = AddableDict({step_name: task.result()})
                                    ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3932, in get_next_chunk
    return await py_anext(generator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5003, in atransform
    async for output in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4967, in _atransform
    output = await acall_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4942, in f
    return await run_in_executor(config, func, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 616, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 607, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4936, in func
    return call_func_with_variable_args(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 428, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 525, in show_tool_outputs
    tool_outputs=call_tools(tool_calls) #工具输出
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 512, in call_tools
    tool_fn = tools.get(tool_name)
              ^^^^^^^^^
AttributeError: 'list' object has no attribute 'get'
-chat_qa_chain_self_answer
2025-07-20 22:03:27,006 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 83, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 642, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 687, in chat_answer
    async for info, answer in self.astream(question, chat_chain,  chain_config, document_variable_names,
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 704, in astream
    async for chunk in chat_chain.astream(chain_config):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3465, in astream
    async for chunk in self.atransform(input_aiter(), config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 647, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 636, in _atransform
    yield await first_map_chunk_task
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3963, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3949, in _atransform
    chunk = AddableDict({step_name: task.result()})
                                    ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3932, in get_next_chunk
    return await py_anext(generator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 95, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2282, in _atransform_stream_with_config
    final_input: Optional[Input] = await py_anext(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1471, in atransform
    async for ichunk in input:
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1471, in atransform
    async for ichunk in input:
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5660, in atransform
    async for item in self.bound.atransform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 647, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 636, in _atransform
    yield await first_map_chunk_task
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3963, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3949, in _atransform
    chunk = AddableDict({step_name: task.result()})
                                    ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3932, in get_next_chunk
    return await py_anext(generator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5003, in atransform
    async for output in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4967, in _atransform
    output = await acall_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4942, in f
    return await run_in_executor(config, func, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 616, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 607, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4936, in func
    return call_func_with_variable_args(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 428, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 524, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3045, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5431, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 378, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 963, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 782, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1028, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1092, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 156, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1043, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1087, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid 'tools': empty array. Expected an array with minimum length 1, but got an empty array instead.", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
-chat_qa_chain_self_answer
2025-07-20 22:04:32,336 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 83, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 642, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 652, in chat_answer
    chat_chain = self.create_chat_chain(document_variable_names=document_variable_names, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 585, in create_chat_chain
    tool_chain = self.create_tool_chain(kwargs["tools"])
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 504, in create_tool_chain
    llm_with_tools = self.llm.bind_tools(tools)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1652, in bind_tools
    convert_to_openai_tool(tool, strict=strict) for tool in tools
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\function_calling.py", line 586, in convert_to_openai_tool
    oai_function = convert_to_openai_function(tool, strict=strict)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\function_calling.py", line 488, in convert_to_openai_function
    raise ValueError(msg)
ValueError: Unsupported function

DuckDuckGoSearch

Functions must be passed in as Dict, pydantic.BaseModel, or Callable. If they're a dict they must either be in OpenAI function format or valid JSON schema with top-level 'title' and 'description' keys.
-chat_qa_chain_self_answer
2025-07-20 22:04:57,940 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 83, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 642, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 652, in chat_answer
    chat_chain = self.create_chat_chain(document_variable_names=document_variable_names, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 585, in create_chat_chain
    tool_chain = self.create_tool_chain(kwargs["tools"])
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 504, in create_tool_chain
    llm_with_tools = self.llm.bind_tools(tools)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1652, in bind_tools
    convert_to_openai_tool(tool, strict=strict) for tool in tools
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\function_calling.py", line 586, in convert_to_openai_tool
    oai_function = convert_to_openai_function(tool, strict=strict)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\function_calling.py", line 488, in convert_to_openai_function
    raise ValueError(msg)
ValueError: Unsupported function

DuckDuckGoSearch

Functions must be passed in as Dict, pydantic.BaseModel, or Callable. If they're a dict they must either be in OpenAI function format or valid JSON schema with top-level 'title' and 'description' keys.
-chat_qa_chain_self_answer
2025-07-21 01:44:27,577 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 84, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 646, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 692, in chat_answer
    async for info, answer in self.astream(question, chat_chain,  chain_config, document_variable_names,
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 709, in astream
    async for chunk in chat_chain.astream(chain_config):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3465, in astream
    async for chunk in self.atransform(input_aiter(), config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 647, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 636, in _atransform
    yield await first_map_chunk_task
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3963, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3949, in _atransform
    chunk = AddableDict({step_name: task.result()})
                                    ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3932, in get_next_chunk
    return await py_anext(generator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 95, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2282, in _atransform_stream_with_config
    final_input: Optional[Input] = await py_anext(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1489, in atransform
    async for output in self.astream(final, config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 598, in astream
    async for chunk in self._astream(
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 2698, in _astream
    async for chunk in super()._astream(*args, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1275, in _astream
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2454, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1784, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1584, in request
    raise self._make_status_error_from_response(err.response) from None
openai.PermissionDeniedError: Error code: 403 - {'error': {'message': '免费API限制模型输入token小于4096，如有更多需求，请访问 https://api.chatanywhere.tech/#/shop 购买付费API。The number of prompt tokens for free accounts is limited to 4096. If you have additional requirements, please visit https://api.chatanywhere.tech/#/shop to purchase a premium key.(当前请求使用的ApiKey: sk-Hsr****fpgt)【如果您遇到问题，欢迎加入QQ群咨询：1048463714】', 'type': 'chatanywhere_error', 'param': None, 'code': '403 FORBIDDEN'}}
-chat_qa_chain_self_answer
2025-07-22 21:18:28,868 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\langchain_community\document_loaders\parsers\pdf.py", line 954, in _lazy_parse
    import pymupdf
  File "C:\Program Files\JetBrains\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'pymupdf'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 90, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 648, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 692, in chat_answer
    new_docs=self.get_docs(upload_files)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 664, in get_docs
    doc = loader[1].load()
          ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\document_loaders\pdf.py", line 853, in load
    return list(self._lazy_load(**kwargs))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\document_loaders\pdf.py", line 850, in _lazy_load
    yield from parser._lazy_parse(blob, text_kwargs=kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_community\document_loaders\parsers\pdf.py", line 991, in _lazy_parse
    raise ImportError(
ImportError: pymupdf package not found, please install it with `pip install pymupdf`
-chat_qa_chain_self_answer
2025-07-23 01:37:17,704 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 648, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 697, in chat_answer
    async for info, answer in self.astream(question, chat_chain,  chain_config, document_variable_names,
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 714, in astream
    async for chunk in chat_chain.astream(chain_config):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3465, in astream
    async for chunk in self.atransform(input_aiter(), config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 647, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 636, in _atransform
    yield await first_map_chunk_task
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3963, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3949, in _atransform
    chunk = AddableDict({step_name: task.result()})
                                    ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3932, in get_next_chunk
    return await py_anext(generator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 95, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2282, in _atransform_stream_with_config
    final_input: Optional[Input] = await py_anext(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1489, in atransform
    async for output in self.astream(final, config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 598, in astream
    async for chunk in self._astream(
  File "C:\anaconda3\Lib\site-packages\langchain_huggingface\chat_models\huggingface.py", line 692, in _astream
    async for chunk in await self.llm.async_client.chat_completion(
                             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\pydantic\main.py", line 991, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'HuggingFacePipeline' object has no attribute 'async_client'
-chat_qa_chain_self_answer
2025-07-23 01:41:00,852 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 648, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 697, in chat_answer
    async for info, answer in self.astream(question, chat_chain,  chain_config, document_variable_names,
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 714, in astream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3438, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 573, in _transform
    for chunk in for_passthrough:
                 ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5647, in transform
    yield from self.bound.transform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4875, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4842, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 428, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 528, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3045, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5431, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 378, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 963, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 782, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1028, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_huggingface\chat_models\huggingface.py", line 577, in _generate
    llm_input = self._to_chat_prompt(messages)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_huggingface\chat_models\huggingface.py", line 731, in _to_chat_prompt
    return self.tokenizer.apply_chat_template(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\transformers\tokenization_utils_base.py", line 1632, in apply_chat_template
    chat_template = self.get_chat_template(chat_template, tools)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\transformers\tokenization_utils_base.py", line 1754, in get_chat_template
    raise ValueError(
ValueError: Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating
-chat_qa_chain_self_answer
2025-07-23 20:00:25,643 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 648, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 697, in chat_answer
    async for info, answer in self.astream(question, chat_chain,  chain_config, document_variable_names,
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 714, in astream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3438, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2178, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5647, in transform
    yield from self.bound.transform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2178, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  [Previous line repeated 1 more time]
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1447, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\branch.py", line 351, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5608, in stream
    yield from self.bound.stream(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4886, in transform
    raise TypeError(msg)
TypeError: Cannot stream a coroutine function synchronously.Use `astream` instead.
-chat_qa_chain_self_answer
2025-07-23 20:40:47,832 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 648, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 697, in chat_answer
    async for info, answer in self.astream(question, chat_chain,  chain_config, document_variable_names,
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 714, in astream
    async for chunk in chat_chain.astream(chain_config):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3465, in astream
    async for chunk in self.atransform(input_aiter(), config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 647, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 636, in _atransform
    yield await first_map_chunk_task
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3963, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3949, in _atransform
    chunk = AddableDict({step_name: task.result()})
                                    ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3932, in get_next_chunk
    return await py_anext(generator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 95, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2282, in _atransform_stream_with_config
    final_input: Optional[Input] = await py_anext(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1489, in atransform
    async for output in self.astream(final, config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 598, in astream
    async for chunk in self._astream(
  File "C:\anaconda3\Lib\site-packages\langchain_huggingface\chat_models\huggingface.py", line 692, in _astream
    async for chunk in await self.llm.async_client.chat_completion(
                             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\pydantic\main.py", line 991, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'HuggingFacePipeline' object has no attribute 'async_client'
-chat_qa_chain_self_answer
2025-07-23 20:50:00,916 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 648, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 697, in chat_answer
    async for info, answer in self.astream(question, chat_chain,  chain_config, document_variable_names,
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 714, in astream
    async for chunk in chat_chain.astream(chain_config):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3465, in astream
    async for chunk in self.atransform(input_aiter(), config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 647, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 636, in _atransform
    yield await first_map_chunk_task
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3963, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3949, in _atransform
    chunk = AddableDict({step_name: task.result()})
                                    ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3932, in get_next_chunk
    return await py_anext(generator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 95, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2282, in _atransform_stream_with_config
    final_input: Optional[Input] = await py_anext(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1489, in atransform
    async for output in self.astream(final, config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 598, in astream
    async for chunk in self._astream(
  File "C:\anaconda3\Lib\site-packages\langchain_huggingface\chat_models\huggingface.py", line 692, in _astream
    async for chunk in await self.llm.async_client.chat_completion(
                             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\pydantic\main.py", line 991, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'HuggingFacePipeline' object has no attribute 'async_client'
-chat_qa_chain_self_answer
2025-07-24 15:21:13,728 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "C:\anaconda3\Lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 488, in _make_request
    raise new_e
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "C:\anaconda3\Lib\site-packages\urllib3\connection.py", line 753, in connect
    self.sock = sock = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\connection.py", line 207, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x000002A9DA376240>, 'Connection to huggingface.co timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\requests\adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002A9DA376240>, 'Connection to huggingface.co timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 624, in answer
    question_token = self.llm.get_num_tokens(question)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 366, in get_num_tokens
    return len(self.get_token_ids(text))
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 353, in get_token_ids
    return _get_token_ids_default_method(text)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 79, in _get_token_ids_default_method
    tokenizer = get_tokenizer()
                ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 73, in get_tokenizer
    return GPT2TokenizerFast.from_pretrained("gpt2")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\transformers\tokenization_utils_base.py", line 1968, in from_pretrained
    for template in list_repo_templates(
                    ^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\transformers\utils\hub.py", line 163, in list_repo_templates
    for entry in list_repo_tree(
                 ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\huggingface_hub\hf_api.py", line 3168, in list_repo_tree
    for path_info in paginate(path=tree_url, headers=headers, params={"recursive": recursive, "expand": expand}):
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\huggingface_hub\utils\_pagination.py", line 36, in paginate
    r = session.get(path, params=params, headers=headers)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\huggingface_hub\utils\_http.py", line 96, in send
    return super().send(request, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\adapters.py", line 688, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002A9DA376240>, 'Connection to huggingface.co timed out. (connect timeout=None)'))"), '(Request ID: 99c353c9-2fba-4503-8fc2-b5a051e3eb8f)')
-chat_qa_chain_self_answer
2025-07-24 15:24:51,970 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "C:\anaconda3\Lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 488, in _make_request
    raise new_e
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "C:\anaconda3\Lib\site-packages\urllib3\connection.py", line 753, in connect
    self.sock = sock = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\connection.py", line 207, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x0000020D4CFC6360>, 'Connection to huggingface.co timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\requests\adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000020D4CFC6360>, 'Connection to huggingface.co timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 624, in answer
    question_token = self.llm.get_num_tokens(question)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 366, in get_num_tokens
    return len(self.get_token_ids(text))
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 353, in get_token_ids
    return _get_token_ids_default_method(text)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 79, in _get_token_ids_default_method
    tokenizer = get_tokenizer()
                ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 73, in get_tokenizer
    return GPT2TokenizerFast.from_pretrained("gpt2")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\transformers\tokenization_utils_base.py", line 1968, in from_pretrained
    for template in list_repo_templates(
                    ^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\transformers\utils\hub.py", line 163, in list_repo_templates
    for entry in list_repo_tree(
                 ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\huggingface_hub\hf_api.py", line 3168, in list_repo_tree
    for path_info in paginate(path=tree_url, headers=headers, params={"recursive": recursive, "expand": expand}):
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\huggingface_hub\utils\_pagination.py", line 36, in paginate
    r = session.get(path, params=params, headers=headers)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\huggingface_hub\utils\_http.py", line 96, in send
    return super().send(request, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\adapters.py", line 688, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000020D4CFC6360>, 'Connection to huggingface.co timed out. (connect timeout=None)'))"), '(Request ID: c1f850ed-75e5-44d2-9f78-d8b657edec64)')
-chat_qa_chain_self_answer
2025-07-24 15:28:13,804 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "C:\anaconda3\Lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 488, in _make_request
    raise new_e
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "C:\anaconda3\Lib\site-packages\urllib3\connection.py", line 753, in connect
    self.sock = sock = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\connection.py", line 207, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x00000208CD15BBC0>, 'Connection to huggingface.co timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\requests\adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000208CD15BBC0>, 'Connection to huggingface.co timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 624, in answer
    question_token = self.llm.get_num_tokens(question)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 366, in get_num_tokens
    return len(self.get_token_ids(text))
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 353, in get_token_ids
    return _get_token_ids_default_method(text)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 79, in _get_token_ids_default_method
    tokenizer = get_tokenizer()
                ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 73, in get_tokenizer
    return GPT2TokenizerFast.from_pretrained("gpt2")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\transformers\tokenization_utils_base.py", line 1968, in from_pretrained
    for template in list_repo_templates(
                    ^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\transformers\utils\hub.py", line 163, in list_repo_templates
    for entry in list_repo_tree(
                 ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\huggingface_hub\hf_api.py", line 3168, in list_repo_tree
    for path_info in paginate(path=tree_url, headers=headers, params={"recursive": recursive, "expand": expand}):
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\huggingface_hub\utils\_pagination.py", line 36, in paginate
    r = session.get(path, params=params, headers=headers)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\huggingface_hub\utils\_http.py", line 96, in send
    return super().send(request, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\adapters.py", line 688, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000208CD15BBC0>, 'Connection to huggingface.co timed out. (connect timeout=None)'))"), '(Request ID: 151bbe97-a0c3-4a6e-aece-e2f63af86c0d)')
-chat_qa_chain_self_answer
2025-07-24 15:29:31,089 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "C:\anaconda3\Lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 488, in _make_request
    raise new_e
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "C:\anaconda3\Lib\site-packages\urllib3\connection.py", line 753, in connect
    self.sock = sock = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\connection.py", line 207, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x0000020D075E8200>, 'Connection to huggingface.co timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\requests\adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000020D075E8200>, 'Connection to huggingface.co timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 624, in answer
    question_token = self.llm.get_num_tokens(question)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 366, in get_num_tokens
    return len(self.get_token_ids(text))
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 353, in get_token_ids
    return _get_token_ids_default_method(text)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 79, in _get_token_ids_default_method
    tokenizer = get_tokenizer()
                ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 73, in get_tokenizer
    return GPT2TokenizerFast.from_pretrained("gpt2")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\transformers\tokenization_utils_base.py", line 1968, in from_pretrained
    for template in list_repo_templates(
                    ^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\transformers\utils\hub.py", line 163, in list_repo_templates
    for entry in list_repo_tree(
                 ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\huggingface_hub\hf_api.py", line 3168, in list_repo_tree
    for path_info in paginate(path=tree_url, headers=headers, params={"recursive": recursive, "expand": expand}):
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\huggingface_hub\utils\_pagination.py", line 36, in paginate
    r = session.get(path, params=params, headers=headers)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\huggingface_hub\utils\_http.py", line 96, in send
    return super().send(request, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\adapters.py", line 688, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000020D075E8200>, 'Connection to huggingface.co timed out. (connect timeout=None)'))"), '(Request ID: 339e07fa-32a3-46c5-9c71-9981e1634b8c)')
-chat_qa_chain_self_answer
2025-07-24 15:31:03,423 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "C:\anaconda3\Lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 488, in _make_request
    raise new_e
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "C:\anaconda3\Lib\site-packages\urllib3\connection.py", line 753, in connect
    self.sock = sock = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\connection.py", line 207, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x0000020D075EB500>, 'Connection to huggingface.co timed out. (connect timeout=None)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\requests\adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000020D075EB500>, 'Connection to huggingface.co timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 624, in answer
    question_token = self.llm.get_num_tokens(question)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 366, in get_num_tokens
    return len(self.get_token_ids(text))
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 353, in get_token_ids
    return _get_token_ids_default_method(text)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 79, in _get_token_ids_default_method
    tokenizer = get_tokenizer()
                ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\base.py", line 73, in get_tokenizer
    return GPT2TokenizerFast.from_pretrained("gpt2")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\transformers\tokenization_utils_base.py", line 1968, in from_pretrained
    for template in list_repo_templates(
                    ^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\transformers\utils\hub.py", line 163, in list_repo_templates
    for entry in list_repo_tree(
                 ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\huggingface_hub\hf_api.py", line 3168, in list_repo_tree
    for path_info in paginate(path=tree_url, headers=headers, params={"recursive": recursive, "expand": expand}):
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\huggingface_hub\utils\_pagination.py", line 36, in paginate
    r = session.get(path, params=params, headers=headers)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\huggingface_hub\utils\_http.py", line 96, in send
    return super().send(request, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\requests\adapters.py", line 688, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000020D075EB500>, 'Connection to huggingface.co timed out. (connect timeout=None)'))"), '(Request ID: 8c82fa22-c884-4930-b86c-1f608de1222e)')
-chat_qa_chain_self_answer
2025-07-24 15:31:17,327 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 648, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 697, in chat_answer
    async for info, answer in self.astream(question, chat_chain,  chain_config, document_variable_names,
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 714, in astream
    async for chunk in chat_chain.astream(chain_config):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3465, in astream
    async for chunk in self.atransform(input_aiter(), config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 647, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 636, in _atransform
    yield await first_map_chunk_task
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3963, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3949, in _atransform
    chunk = AddableDict({step_name: task.result()})
                                    ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3932, in get_next_chunk
    return await py_anext(generator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 95, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2282, in _atransform_stream_with_config
    final_input: Optional[Input] = await py_anext(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1489, in atransform
    async for output in self.astream(final, config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 598, in astream
    async for chunk in self._astream(
  File "C:\anaconda3\Lib\site-packages\langchain_huggingface\chat_models\huggingface.py", line 692, in _astream
    async for chunk in await self.llm.async_client.chat_completion(
                             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\pydantic\main.py", line 991, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'HuggingFacePipeline' object has no attribute 'async_client'
-chat_qa_chain_self_answer
2025-07-24 15:55:18,943 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 647, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 682, in chat_answer
    chat_chain = self.create_chat_chain(document_variable_names=document_variable_names, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 591, in create_chat_chain
    tool_chain = self.create_tool_chain(kwargs["tools"])
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 506, in create_tool_chain
    llm_with_tools = self.llm.bind_tools(list(tools.values()))
                     ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\pydantic\main.py", line 991, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'HuggingFacePipeline' object has no attribute 'bind_tools'
-chat_qa_chain_self_answer
2025-07-24 16:07:42,187 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 650, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 699, in chat_answer
    async for info, answer in self.astream(question, chat_chain,  chain_config, document_variable_names,
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 716, in astream
    async for chunk in chat_chain.astream(chain_config):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3465, in astream
    async for chunk in self.atransform(input_aiter(), config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 647, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 636, in _atransform
    yield await first_map_chunk_task
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3963, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3949, in _atransform
    chunk = AddableDict({step_name: task.result()})
                                    ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3932, in get_next_chunk
    return await py_anext(generator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 95, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2282, in _atransform_stream_with_config
    final_input: Optional[Input] = await py_anext(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 78, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1489, in atransform
    async for output in self.astream(final, config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\llms.py", line 631, in astream
    async for chunk in self._astream(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\llms.py", line 747, in _astream
    item = await run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 616, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 607, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_huggingface\llms\huggingface_pipeline.py", line 400, in _stream
    for char in streamer:
                ^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\transformers\generation\streamers.py", line 226, in __next__
    value = self.text_queue.get(timeout=self.timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\queue.py", line 179, in get
    raise Empty
_queue.Empty
-chat_qa_chain_self_answer
2025-07-24 16:11:10,486 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    async for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 650, in answer
    async for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 699, in chat_answer
    async for info, answer in self.astream(question, chat_chain,  chain_config, document_variable_names,
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 716, in astream
    async for chunk in chat_chain.astream(chain_config):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3465, in astream
    async for chunk in self.atransform(input_aiter(), config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 647, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 637, in _atransform
    async for chunk in map_output:
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3963, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3949, in _atransform
    chunk = AddableDict({step_name: task.result()})
                                    ^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3932, in get_next_chunk
    return await py_anext(generator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3447, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3414, in _atransform
    async for output in final_pipeline:
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 95, in atransform
    async for chunk in self._atransform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2322, in _atransform_stream_with_config
    chunk = await coro_with_context(py_anext(iterator), context)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 47, in _atransform
    async for chunk in input:
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\aiter.py", line 133, in tee_peer
    item = await iterator.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1489, in atransform
    async for output in self.astream(final, config, **kwargs):
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\llms.py", line 631, in astream
    async for chunk in self._astream(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\llms.py", line 747, in _astream
    item = await run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 616, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 607, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_huggingface\llms\huggingface_pipeline.py", line 400, in _stream
    for char in streamer:
                ^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\transformers\generation\streamers.py", line 226, in __next__
    value = self.text_queue.get(timeout=self.timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\queue.py", line 179, in get
    raise Empty
_queue.Empty
-chat_qa_chain_self_answer
2025-07-24 18:36:14,258 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
TypeError: 'async_generator' object is not iterable
-chat_qa_chain_self_answer
2025-09-28 00:52:24,277 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 644, in answer
    abstract_answer = self.abstract_answer(files=files, mode=kwargs["abstract_mode"], **kwargs)
                                                             ~~~~~~^^^^^^^^^^^^^^^^^
KeyError: 'abstract_mode'
-chat_qa_chain_self_answer
2025-09-28 11:19:24,524 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3438, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2178, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5647, in transform
    yield from self.bound.transform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4875, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4842, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 428, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3045, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5431, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 378, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 963, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 782, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1028, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1092, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 156, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1043, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1087, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.InternalServerError: Error code: 502
-chat_qa_chain_self_answer
2025-09-28 11:19:54,435 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3438, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2178, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5647, in transform
    yield from self.bound.transform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4875, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4842, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 428, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3045, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5431, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 378, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 963, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 782, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1028, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1092, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 156, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1043, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1087, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.InternalServerError: Error code: 502
-chat_qa_chain_self_answer
2025-09-28 11:44:13,469 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3438, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2178, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5647, in transform
    yield from self.bound.transform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4875, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4842, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 428, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3045, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5431, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 378, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 963, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 782, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1028, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 669, in _generate
    resp = self.completion_with_retry(**params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 540, in completion_with_retry
    return _completion_with_retry(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\tenacity\__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 538, in _completion_with_retry
    return check_response(resp)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\llms\tongyi.py", line 61, in check_response
    raise ValueError(
ValueError: request_id: 1247d8e8-d56f-44fa-9141-85c147b19eb8 
 status_code: 400 
 code: Arrearage 
 message: Access denied, please make sure your account is in good standing.
-chat_qa_chain_self_answer
2025-09-28 11:44:29,738 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3438, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2178, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5647, in transform
    yield from self.bound.transform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4875, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4842, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 428, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3045, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5431, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 378, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 963, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 782, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1028, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 669, in _generate
    resp = self.completion_with_retry(**params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 540, in completion_with_retry
    return _completion_with_retry(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\tenacity\__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 538, in _completion_with_retry
    return check_response(resp)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\llms\tongyi.py", line 61, in check_response
    raise ValueError(
ValueError: request_id: 379f3cce-aa9d-4f66-889b-e40cfb29e4ac 
 status_code: 400 
 code: Arrearage 
 message: Access denied, please make sure your account is in good standing.
-chat_qa_chain_self_answer
2025-09-28 11:44:44,382 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3438, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2178, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5647, in transform
    yield from self.bound.transform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4875, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4842, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 428, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3045, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5431, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 378, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 963, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 782, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1028, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\chat_models\baichuan.py", line 462, in _generate
    raise ValueError(f"Error from Baichuan api response: {res}")
ValueError: Error from Baichuan api response: <Response [404]>
-chat_qa_chain_self_answer
2025-09-28 11:45:06,084 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3438, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2178, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5647, in transform
    yield from self.bound.transform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4875, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4842, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 428, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3045, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5431, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 378, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 963, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 782, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1028, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1092, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 156, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1043, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1087, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': 'User location is not supported for the API use.', 'status': 'FAILED_PRECONDITION'}}]
-chat_qa_chain_self_answer
2025-09-28 15:45:28,819 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3438, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2178, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5647, in transform
    yield from self.bound.transform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4875, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4842, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 428, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3045, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5431, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 378, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 963, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 782, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1028, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1092, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 156, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1043, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1087, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Your account org-b58fa3daaec74bbea30dcf9357471395 <ak-ey4g5asgsu6111ej6i6i> is suspended, please check your plan and billing details', 'type': 'exceeded_current_quota_error'}}
-chat_qa_chain_self_answer
2025-09-28 15:53:24,398 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3438, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2178, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5647, in transform
    yield from self.bound.transform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4875, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4842, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 428, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3045, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5431, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 378, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 963, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 782, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1028, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1092, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 156, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1043, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1087, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid 'tools': empty array. Expected an array with minimum length 1, but got an empty array instead.", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
-chat_qa_chain_self_answer
2025-09-28 16:04:01,087 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3438, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2178, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5647, in transform
    yield from self.bound.transform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4875, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4842, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 428, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3045, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5431, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 378, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 963, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 782, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1028, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1092, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 156, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1043, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1087, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid 'tools': empty array. Expected an array with minimum length 1, but got an empty array instead.", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
-chat_qa_chain_self_answer
2025-09-28 16:06:39,499 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3438, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3424, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3386, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2178, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1429, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5647, in transform
    yield from self.bound.transform(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 595, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 584, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3892, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3876, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4875, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2215, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4842, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 428, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3045, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5431, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 378, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 963, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 782, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1028, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1092, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 156, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1043, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1087, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid 'tools': empty array. Expected an array with minimum length 1, but got an empty array instead.", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
-chat_qa_chain_self_answer
2025-09-28 17:01:34,944 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3649, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2332, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1586, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5887, in stream
    yield from self.bound.stream(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5128, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5095, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3243, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5710, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1023, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 840, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1089, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1143, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 173, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1102, in _stream
    generation_chunk = self._convert_chunk_to_generation_chunk(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 909, in _convert_chunk_to_generation_chunk
    message_chunk = _convert_delta_to_message_chunk(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 340, in _convert_delta_to_message_chunk
    name=rtc["function"].get("name"),
         ~~~^^^^^^^^^^^^
TypeError: string indices must be integers, not 'str'
-chat_qa_chain_self_answer
2025-09-28 17:02:20,786 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3649, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2332, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1586, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5887, in stream
    yield from self.bound.stream(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5128, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5095, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3243, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5710, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1023, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 840, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1089, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1143, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 173, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1102, in _stream
    generation_chunk = self._convert_chunk_to_generation_chunk(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 909, in _convert_chunk_to_generation_chunk
    message_chunk = _convert_delta_to_message_chunk(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 340, in _convert_delta_to_message_chunk
    name=rtc["function"].get("name"),
         ~~~^^^^^^^^^^^^
TypeError: string indices must be integers, not 'str'
-chat_qa_chain_self_answer
2025-09-28 17:08:33,609 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 734, in stream
    self.chat_history[-1][1] += f"<b>工具调用：</b><br>{tool_result } <br> "
    ~~~~~~~~~~~~~~~~~^^^^
IndexError: list index out of range
-chat_qa_chain_self_answer
2025-09-28 17:14:52,760 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3649, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2332, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1586, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5887, in stream
    yield from self.bound.stream(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5128, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5095, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3243, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5710, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1023, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 840, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1089, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1143, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 173, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1094, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'gpt-4.1-ca模型免费API限制每日5次请求，请00:00后再试，如有更多需求，请访问 https://api.chatanywhere.tech/#/shop 购买付费API。The free account is limited to 5 requests per day. Please try again after 00:00 the next day. If you have additional requirements, please visit https://api.chatanywhere.tech/#/shop to purchase a premium key.(当前请求使用的ApiKey: sk-Hsr****fpgt)【如果您遇到问题，欢迎加入QQ群咨询：1048463714】', 'type': 'chatanywhere_error', 'param': None, 'code': '429 TOO_MANY_REQUESTS'}}
-chat_qa_chain_self_answer
2025-09-28 17:24:33,010 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3649, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2332, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1586, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5887, in stream
    yield from self.bound.stream(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5128, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5095, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3243, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5710, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1023, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 840, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1089, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\chat_models\baichuan.py", line 462, in _generate
    raise ValueError(f"Error from Baichuan api response: {res}")
ValueError: Error from Baichuan api response: <Response [404]>
-chat_qa_chain_self_answer
2025-09-28 17:25:09,618 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3649, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2332, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1586, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5887, in stream
    yield from self.bound.stream(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5128, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5095, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3243, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5710, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1023, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 840, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1089, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1143, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 173, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1094, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-1.5-flash is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]
-chat_qa_chain_self_answer
2025-09-28 17:25:50,458 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3649, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2332, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1586, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5887, in stream
    yield from self.bound.stream(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5128, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5095, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3243, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5710, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1023, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 840, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1089, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1143, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 173, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1094, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.InternalServerError: Error code: 502
-chat_qa_chain_self_answer
2025-09-28 17:58:48,228 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3649, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2332, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1586, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5887, in stream
    yield from self.bound.stream(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5128, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5095, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3243, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5710, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1023, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 840, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1089, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1143, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 173, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1094, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-1.5-flash is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]
-chat_qa_chain_self_answer
2025-09-28 18:01:10,693 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3649, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2332, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1586, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5887, in stream
    yield from self.bound.stream(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5128, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5095, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3243, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5710, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1023, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 840, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1089, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1143, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 173, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1094, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-2.5-pro-exp-03-25 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]
-chat_qa_chain_self_answer
2025-09-28 18:26:52,520 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3649, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 592, in _transform
    for chunk in for_passthrough:
                 ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1586, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5887, in stream
    yield from self.bound.stream(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5128, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5095, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3243, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5710, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1023, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 840, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1089, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1143, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 173, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1094, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-1.5-flash is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]
-chat_qa_chain_self_answer
2025-09-28 19:02:13,480 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3649, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2332, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1586, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5887, in stream
    yield from self.bound.stream(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5128, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5095, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3243, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5710, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1023, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 840, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1089, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\chat_models\baichuan.py", line 462, in _generate
    raise ValueError(f"Error from Baichuan api response: {res}")
ValueError: Error from Baichuan api response: <Response [404]>
-chat_qa_chain_self_answer
2025-09-28 19:02:23,937 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3649, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2332, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1568, in transform
    for ichunk in input:
                  ^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1586, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5887, in stream
    yield from self.bound.stream(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5128, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5095, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3243, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 5710, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1023, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 840, in generate
    self._generate_with_cache(
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1089, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\chat_models\baichuan.py", line 462, in _generate
    raise ValueError(f"Error from Baichuan api response: {res}")
ValueError: Error from Baichuan api response: <Response [404]>
-chat_qa_chain_self_answer
2025-09-28 19:06:25,781 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3649, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2332, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1586, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\chat_models\baichuan.py", line 475, in _stream
    raise ValueError(f"Error from Baichuan api response: {res}")
ValueError: Error from Baichuan api response: <Response [404]>
-chat_qa_chain_self_answer
2025-09-28 19:06:45,629 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3649, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2332, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1586, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\chat_models\baichuan.py", line 475, in _stream
    raise ValueError(f"Error from Baichuan api response: {res}")
ValueError: Error from Baichuan api response: <Response [404]>
-chat_qa_chain_self_answer
2025-09-28 19:13:33,126 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3649, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4118, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 4102, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3635, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2369, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 3594, in _transform
    yield from final_pipeline
  File "C:\anaconda3\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 2332, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_core\runnables\base.py", line 1586, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_openai\chat_models\base.py", line 1094, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: Completions.create() got an unexpected keyword argument 'top_k'
-chat_qa_chain_self_answer
2025-09-28 19:24:09,454 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\anaconda3\Lib\site-packages\langchain_community\retrievers\bm25.py", line 55, in from_texts
    from rank_bm25 import BM25Okapi
  File "C:\Program Files\JetBrains\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'rank_bm25'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 649, in answer
    self.get_retriever(**kwargs)
  File "C:\Users\Xufei Chen\Desktop\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 212, in get_retriever
    self.bm25_retriever = BM25Retriever.from_documents(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\retrievers\bm25.py", line 102, in from_documents
    return cls.from_texts(
           ^^^^^^^^^^^^^^^
  File "C:\anaconda3\Lib\site-packages\langchain_community\retrievers\bm25.py", line 57, in from_texts
    raise ImportError(
ImportError: Could not import rank_bm25, please install with `pip install rank_bm25`.
-chat_qa_chain_self_answer
2025-10-05 15:07:14,597 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1043, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1087, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': 'User location is not supported for the API use.', 'status': 'FAILED_PRECONDITION'}}]
-chat_qa_chain_self_answer
2025-10-05 19:44:33,234 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 428, in web_search
    results = ddgs.text(query, max_results=kwargs["max_results"])
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\duckduckgo_search\duckduckgo_search.py", line 185, in text
    raise DuckDuckGoSearchException(err)
duckduckgo_search.exceptions.DuckDuckGoSearchException: https://html.duckduckgo.com/html RuntimeError: error sending request for url (https://html.duckduckgo.com/html): operation timed out

Caused by:
    operation timed out
-chat_qa_chain_self_answer
2025-10-05 19:46:14,981 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 535, in show_tool_outputs
    tool_outputs=call_tools(tool_calls) #工具输出
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 522, in call_tools
    msg = tool_fn.invoke(tool_call)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\base.py", line 610, in invoke
    return self.run(tool_input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\base.py", line 895, in run
    raise error_to_raise
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\base.py", line 864, in run
    response = context.run(self._run, *tool_args, **tool_kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\tools\ddg_search\tool.py", line 112, in _run
    raw_results = self.api_wrapper.results(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\utilities\duckduckgo_search.py", line 146, in results
    for r in self._ddgs_text(query, max_results=max_results)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\utilities\duckduckgo_search.py", line 64, in _ddgs_text
    ddgs_gen = ddgs.text(
               ^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\duckduckgo_search\duckduckgo_search.py", line 185, in text
    raise DuckDuckGoSearchException(err)
duckduckgo_search.exceptions.DuckDuckGoSearchException: https://lite.duckduckgo.com/lite/ RuntimeError: error sending request for url (https://lite.duckduckgo.com/lite/): operation timed out

Caused by:
    operation timed out
-chat_qa_chain_self_answer
2025-10-05 19:51:43,277 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3244, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5711, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 909, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 844, in _chat_stream_with_aggregation
    for chunk in self._iterate_over_stream(messages, stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 933, in _iterate_over_stream
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 831, in _create_chat_stream
    yield from self._client.chat(**chat_params)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\ollama\_client.py", line 179, in inner
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: registry.ollama.ai/library/deepseek-r1:1.5b does not support tools (status code: 400)
-chat_qa_chain_self_answer
2025-10-05 19:53:04,845 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 994, in _stream
    for chunk in self._iterate_over_stream(messages, stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 933, in _iterate_over_stream
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 831, in _create_chat_stream
    yield from self._client.chat(**chat_params)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\ollama\_client.py", line 179, in inner
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)
-chat_qa_chain_self_answer
2025-10-05 19:53:27,544 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 994, in _stream
    for chunk in self._iterate_over_stream(messages, stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 933, in _iterate_over_stream
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 831, in _create_chat_stream
    yield from self._client.chat(**chat_params)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\ollama\_client.py", line 179, in inner
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)
-chat_qa_chain_self_answer
2025-10-05 20:25:12,026 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 428, in web_search
    results = ddgs.text(query, max_results=kwargs["max_results"])
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\duckduckgo_search\duckduckgo_search.py", line 185, in text
    raise DuckDuckGoSearchException(err)
duckduckgo_search.exceptions.DuckDuckGoSearchException: https://html.duckduckgo.com/html RuntimeError: error sending request for url (https://html.duckduckgo.com/html): operation timed out

Caused by:
    operation timed out
-chat_qa_chain_self_answer
2025-10-05 20:26:40,164 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 428, in web_search
    results = ddgs.text(query, max_results=kwargs["max_results"])
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\duckduckgo_search\duckduckgo_search.py", line 185, in text
    raise DuckDuckGoSearchException(err)
duckduckgo_search.exceptions.DuckDuckGoSearchException: https://html.duckduckgo.com/html RuntimeError: error sending request for url (https://html.duckduckgo.com/html): operation timed out

Caused by:
    operation timed out
-chat_qa_chain_self_answer
2025-10-05 20:29:42,276 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 428, in web_search
    results = ddgs.text(query, max_results=kwargs["max_results"])
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\duckduckgo_search\duckduckgo_search.py", line 185, in text
    raise DuckDuckGoSearchException(err)
duckduckgo_search.exceptions.DuckDuckGoSearchException: https://html.duckduckgo.com/html RuntimeError: error sending request for url (https://html.duckduckgo.com/html): operation timed out

Caused by:
    operation timed out
-chat_qa_chain_self_answer
2025-10-05 20:35:58,103 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 428, in web_search
    results = ddgs.text(query, max_results=kwargs["max_results"])
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\duckduckgo_search\duckduckgo_search.py", line 185, in text
    raise DuckDuckGoSearchException(err)
duckduckgo_search.exceptions.DuckDuckGoSearchException: https://lite.duckduckgo.com/lite/ RuntimeError: error sending request for url (https://lite.duckduckgo.com/lite/): operation timed out

Caused by:
    operation timed out
-chat_qa_chain_self_answer
2025-10-05 20:40:30,866 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 428, in web_search
    results = ddgs.text(query, max_results=kwargs["max_results"])
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\duckduckgo_search\duckduckgo_search.py", line 185, in text
    raise DuckDuckGoSearchException(err)
duckduckgo_search.exceptions.DuckDuckGoSearchException: https://lite.duckduckgo.com/lite/ RuntimeError: error sending request for url (https://lite.duckduckgo.com/lite/): operation timed out

Caused by:
    operation timed out
-chat_qa_chain_self_answer
2025-10-05 20:40:40,002 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3244, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5711, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 909, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 844, in _chat_stream_with_aggregation
    for chunk in self._iterate_over_stream(messages, stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 933, in _iterate_over_stream
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 831, in _create_chat_stream
    yield from self._client.chat(**chat_params)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\ollama\_client.py", line 179, in inner
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError:  (status code: 502)
-chat_qa_chain_self_answer
2025-10-05 20:41:08,059 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 994, in _stream
    for chunk in self._iterate_over_stream(messages, stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 933, in _iterate_over_stream
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 831, in _create_chat_stream
    yield from self._client.chat(**chat_params)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\ollama\_client.py", line 179, in inner
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError:  (status code: 502)
-chat_qa_chain_self_answer
2025-10-05 20:44:18,446 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 994, in _stream
    for chunk in self._iterate_over_stream(messages, stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 933, in _iterate_over_stream
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 831, in _create_chat_stream
    yield from self._client.chat(**chat_params)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\ollama\_client.py", line 179, in inner
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError:  (status code: 502)
-chat_qa_chain_self_answer
2025-10-05 21:01:03,196 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\model_to_llm.py", line 186, in model_to_llm
    llm = AutoModelForCausalLM.from_pretrained(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\modeling_utils.py", line 309, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\modeling_utils.py", line 4390, in from_pretrained
    hf_quantizer.validate_environment(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\quantizers\quantizer_bnb_8bit.py", line 73, in validate_environment
    raise ImportError(
ImportError: Using `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 626, in answer
    self.param_set(**kwargs)
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 143, in param_set
    self.llm = model_to_llm(
               ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\model_to_llm.py", line 232, in model_to_llm
    del tokenizer,llm,pipe,llm_model
        ^^^^^^^^^
UnboundLocalError: cannot access local variable 'tokenizer' where it is not associated with a value
-chat_qa_chain_self_answer
2025-10-05 21:01:22,074 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\model_to_llm.py", line 186, in model_to_llm
    llm = AutoModelForCausalLM.from_pretrained(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\modeling_utils.py", line 309, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\modeling_utils.py", line 4390, in from_pretrained
    hf_quantizer.validate_environment(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\quantizers\quantizer_bnb_8bit.py", line 73, in validate_environment
    raise ImportError(
ImportError: Using `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 626, in answer
    self.param_set(**kwargs)
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 143, in param_set
    self.llm = model_to_llm(
               ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\model_to_llm.py", line 232, in model_to_llm
    del tokenizer,llm,pipe,llm_model
        ^^^^^^^^^
UnboundLocalError: cannot access local variable 'tokenizer' where it is not associated with a value
-chat_qa_chain_self_answer
2025-10-05 21:18:06,090 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\model_to_llm.py", line 186, in model_to_llm
    llm = AutoModelForCausalLM.from_pretrained(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\modeling_utils.py", line 309, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\modeling_utils.py", line 4574, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\modeling_utils.py", line 5031, in _load_pretrained_model
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\modeling_utils.py", line 784, in _load_state_dict_into_meta_model
    param = empty_param.to(tensor_device)  # It is actually not empty!
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 2.93 GiB is allocated by PyTorch, and 36.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 626, in answer
    self.param_set(**kwargs)
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 143, in param_set
    self.llm = model_to_llm(
               ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\model_to_llm.py", line 232, in model_to_llm
    del tokenizer,llm,pipe,llm_model
        ^^^^^^^^^
UnboundLocalError: cannot access local variable 'tokenizer' where it is not associated with a value
-chat_qa_chain_self_answer
2025-10-05 23:04:30,076 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 483, in validate_environment
    import dashscope
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'dashscope'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 626, in answer
    self.param_set(**kwargs)
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 143, in param_set
    self.llm = model_to_llm(
               ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\model_to_llm.py", line 305, in model_to_llm
    llm = ChatTongyi(model=model, temperature=temperature, max_tokens=max_tokens,
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\load\serializable.py", line 115, in __init__
    super().__init__(*args, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\pydantic\main.py", line 214, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\pydantic\_internal\_decorators_v1.py", line 148, in _wrapper1
    return validator(values)
           ^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\pydantic.py", line 185, in wrapper
    return func(cls, values)
           ^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 485, in validate_environment
    raise ImportError(
ImportError: Could not import dashscope python package. Please install it with `pip install dashscope --upgrade`.
-chat_qa_chain_self_answer
2025-10-05 23:11:35,272 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3244, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5711, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 669, in _generate
    resp = self.completion_with_retry(**params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 540, in completion_with_retry
    return _completion_with_retry(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\tenacity\__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 538, in _completion_with_retry
    return check_response(resp)
           ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\llms\tongyi.py", line 61, in check_response
    raise ValueError(
ValueError: request_id: f68ffb45-174c-4e41-92e3-786cddff9e5d 
 status_code: 400 
 code: InvalidParameter 
 message: parameter.enable_thinking must be set to false for non-streaming calls
-chat_qa_chain_self_answer
2025-10-05 23:16:28,480 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3244, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5711, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 669, in _generate
    resp = self.completion_with_retry(**params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 540, in completion_with_retry
    return _completion_with_retry(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\tenacity\__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 538, in _completion_with_retry
    return check_response(resp)
           ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\llms\tongyi.py", line 61, in check_response
    raise ValueError(
ValueError: request_id: 61ef1bbb-fefb-45a7-b6b7-1a295384dc31 
 status_code: 400 
 code: InvalidParameter 
 message: parameter.enable_thinking must be set to false for non-streaming calls
-chat_qa_chain_self_answer
2025-10-05 23:34:04,130 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3244, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5711, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 669, in _generate
    resp = self.completion_with_retry(**params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 540, in completion_with_retry
    return _completion_with_retry(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\tenacity\__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 538, in _completion_with_retry
    return check_response(resp)
           ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\llms\tongyi.py", line 61, in check_response
    raise ValueError(
ValueError: request_id: 60ee43e5-7004-48bc-86ae-75fd88fff59a 
 status_code: 400 
 code: InvalidParameter 
 message: This model only support stream mode, please enable the stream parameter to access the model. 
-chat_qa_chain_self_answer
2025-10-05 23:57:41,493 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connectionpool.py", line 773, in urlopen
    self._prepare_proxy(conn)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connectionpool.py", line 1042, in _prepare_proxy
    conn.connect()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connection.py", line 790, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connection.py", line 969, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
               ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\ssl_.py", line 480, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\ssl_.py", line 524, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 455, in wrap_socket
    return self.sslsocket_class._create(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 1041, in _create
    self.do_handshake()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 1319, in do_handshake
    self._sslobj.do_handshake()
ConnectionAbortedError: [WinError 10053] 你的主机中的软件中止了一个已建立的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connectionpool.py", line 773, in urlopen
    self._prepare_proxy(conn)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connectionpool.py", line 1042, in _prepare_proxy
    conn.connect()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connection.py", line 790, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connection.py", line 969, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
               ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\ssl_.py", line 480, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\ssl_.py", line 524, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 455, in wrap_socket
    return self.sslsocket_class._create(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 1041, in _create
    self.do_handshake()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 1319, in do_handshake
    self._sslobj.do_handshake()
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionAbortedError(10053, '你的主机中的软件中止了一个已建立的连接。', None, 10053, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 535, in show_tool_outputs
    tool_outputs=call_tools(tool_calls) #工具输出
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 522, in call_tools
    msg = tool_fn.invoke(tool_call)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\base.py", line 610, in invoke
    return self.run(tool_input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\base.py", line 895, in run
    raise error_to_raise
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\base.py", line 864, in run
    response = context.run(self._run, *tool_args, **tool_kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\structured.py", line 93, in _run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\utilities\google_serper.py", line 74, in run
    results = self._google_serper_api_results(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\utilities\google_serper.py", line 161, in _google_serper_api_results
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\adapters.py", line 659, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionAbortedError(10053, '你的主机中的软件中止了一个已建立的连接。', None, 10053, None))
-chat_qa_chain_self_answer
2025-10-06 00:08:00,078 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 604, in _transform
    for chunk in map_output:
                 ^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 37, in _transform
    for chunk in input:
                 ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 728, in _stream
    for stream_resp, is_last_chunk in generate_with_last_element_mark(
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\llms\tongyi.py", line 139, in generate_with_last_element_mark
    for next_item in iterator:
                     ^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\chat_models\tongyi.py", line 577, in _stream_completion_with_retry
    yield check_response(resp)
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\llms\tongyi.py", line 61, in check_response
    raise ValueError(
ValueError: request_id: 9ba75e7c-ec5f-420a-bbed-22effbb7ba1a 
 status_code: 400 
 code: DataInspectionFailed 
 message: Output data may contain inappropriate content.
-chat_qa_chain_self_answer
2025-10-06 00:08:37,747 - dashscope - ERROR - -_handle_request
2025-10-06 00:09:36,262 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connectionpool.py", line 773, in urlopen
    self._prepare_proxy(conn)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connectionpool.py", line 1042, in _prepare_proxy
    conn.connect()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connection.py", line 790, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connection.py", line 969, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
               ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\ssl_.py", line 480, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\ssl_.py", line 524, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 455, in wrap_socket
    return self.sslsocket_class._create(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 1041, in _create
    self.do_handshake()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 1319, in do_handshake
    self._sslobj.do_handshake()
ConnectionAbortedError: [WinError 10053] 你的主机中的软件中止了一个已建立的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connectionpool.py", line 773, in urlopen
    self._prepare_proxy(conn)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connectionpool.py", line 1042, in _prepare_proxy
    conn.connect()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connection.py", line 790, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connection.py", line 969, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
               ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\ssl_.py", line 480, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\ssl_.py", line 524, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 455, in wrap_socket
    return self.sslsocket_class._create(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 1041, in _create
    self.do_handshake()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 1319, in do_handshake
    self._sslobj.do_handshake()
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionAbortedError(10053, '你的主机中的软件中止了一个已建立的连接。', None, 10053, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 535, in show_tool_outputs
    tool_outputs=call_tools(tool_calls) #工具输出
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 522, in call_tools
    msg = tool_fn.invoke(tool_call)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\base.py", line 610, in invoke
    return self.run(tool_input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\base.py", line 895, in run
    raise error_to_raise
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\base.py", line 864, in run
    response = context.run(self._run, *tool_args, **tool_kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\structured.py", line 93, in _run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\utilities\google_serper.py", line 74, in run
    results = self._google_serper_api_results(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\utilities\google_serper.py", line 161, in _google_serper_api_results
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\adapters.py", line 659, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionAbortedError(10053, '你的主机中的软件中止了一个已建立的连接。', None, 10053, None))
-chat_qa_chain_self_answer
2025-10-06 00:13:06,946 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 532, in show_tool_outputs
    tool_calls=get_tool_calls.invoke(input) #工具调用
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3244, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5711, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 909, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 844, in _chat_stream_with_aggregation
    for chunk in self._iterate_over_stream(messages, stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 933, in _iterate_over_stream
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_ollama\chat_models.py", line 831, in _create_chat_stream
    yield from self._client.chat(**chat_params)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\ollama\_client.py", line 179, in inner
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: registry.ollama.ai/library/gemma3:1b does not support tools (status code: 400)
-chat_qa_chain_self_answer
2025-10-06 00:14:33,085 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connectionpool.py", line 773, in urlopen
    self._prepare_proxy(conn)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connectionpool.py", line 1042, in _prepare_proxy
    conn.connect()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connection.py", line 790, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connection.py", line 969, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
               ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\ssl_.py", line 480, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\ssl_.py", line 524, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 455, in wrap_socket
    return self.sslsocket_class._create(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 1041, in _create
    self.do_handshake()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 1319, in do_handshake
    self._sslobj.do_handshake()
ConnectionAbortedError: [WinError 10053] 你的主机中的软件中止了一个已建立的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connectionpool.py", line 773, in urlopen
    self._prepare_proxy(conn)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connectionpool.py", line 1042, in _prepare_proxy
    conn.connect()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connection.py", line 790, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\connection.py", line 969, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
               ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\ssl_.py", line 480, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\urllib3\util\ssl_.py", line 524, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 455, in wrap_socket
    return self.sslsocket_class._create(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 1041, in _create
    self.do_handshake()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\ssl.py", line 1319, in do_handshake
    self._sslobj.do_handshake()
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionAbortedError(10053, '你的主机中的软件中止了一个已建立的连接。', None, 10053, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 535, in show_tool_outputs
    tool_outputs=call_tools(tool_calls) #工具输出
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 522, in call_tools
    msg = tool_fn.invoke(tool_call)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\base.py", line 610, in invoke
    return self.run(tool_input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\base.py", line 895, in run
    raise error_to_raise
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\base.py", line 864, in run
    response = context.run(self._run, *tool_args, **tool_kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\structured.py", line 93, in _run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\utilities\google_serper.py", line 74, in run
    results = self._google_serper_api_results(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\utilities\google_serper.py", line 161, in _google_serper_api_results
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\requests\adapters.py", line 659, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionAbortedError(10053, '你的主机中的软件中止了一个已建立的连接。', None, 10053, None))
-chat_qa_chain_self_answer
2025-10-06 17:19:02,921 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_openai\chat_models\base.py", line 1043, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1087, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': '1113', 'message': '余额不足或无可用资源包,请充值。'}}
-chat_qa_chain_self_answer
2025-10-06 17:27:06,656 - backoff - INFO - Backing off send_request(...) for 0.7s (requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionAbortedError(10053, '你的主机中的软件中止了一个已建立的连接。', None, 10053, None)))-_log_backoff
2025-10-06 18:41:25,588 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_openai\chat_models\base.py", line 1043, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1087, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': 'rpm_rate_limit_exceeded', 'message': 'Rate limit reached for RPM', 'type': 'rate_limit_exceeded'}, 'id': 'as-cunewje6ph'}
-chat_qa_chain_self_answer
2025-10-06 18:41:44,654 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 651, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 700, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 717, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_openai\chat_models\base.py", line 1043, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1087, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': 'rpm_rate_limit_exceeded', 'message': 'Rate limit reached for RPM', 'type': 'rate_limit_exceeded'}, 'id': 'as-hd5e8rgvfd'}
-chat_qa_chain_self_answer
2025-10-07 16:30:24,180 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 652, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 701, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 759, in stream
    if delta.get("content",False):#开始输出正式回答
       ^^^^^^^^^
AttributeError: 'str' object has no attribute 'get'
-chat_qa_chain_self_answer
2025-10-07 17:16:12,850 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 652, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 701, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 759, in stream
    if delta.get("content",False):#开始输出正式回答
       ^^^^^^^^^
AttributeError: 'str' object has no attribute 'get'
-chat_qa_chain_self_answer
2025-10-07 17:18:08,309 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 652, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 701, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 745, in stream
    if delta["additional_kwargs"].get("reasoning_content", False):
       ~~~~~^^^^^^^^^^^^^^^^^^^^^
TypeError: string indices must be integers, not 'str'
-chat_qa_chain_self_answer
2025-10-07 17:24:02,933 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 652, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 701, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 767, in stream
    delta= delta["additional_kwargs"][
           ~~~~~^^^^^^^^^^^^^^^^^^^^^
KeyError: 'additional_kwargs'
-chat_qa_chain_self_answer
2025-10-07 17:37:24,858 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 652, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 701, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 759, in stream
    if delta.get("content",False):#开始输出正式回答
       ^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\pydantic\main.py", line 892, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'AIMessageChunk' object has no attribute 'get'
-chat_qa_chain_self_answer
2025-10-07 18:10:11,153 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 652, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 701, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 730, in stream
    delta=chunk.get("answer", AIMessageChunk())
                              ^^^^^^^^^^^^^^^^
TypeError: AIMessage.__init__() missing 1 required positional argument: 'content'
-chat_qa_chain_self_answer
2025-10-07 18:13:44,568 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 652, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 701, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 773, in stream
    answer += delta
TypeError: can only concatenate str (not "AIMessageChunk") to str
-chat_qa_chain_self_answer
2025-10-08 00:23:43,052 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 652, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 701, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 721, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 534, in show_tool_outputs
    tool_outputs=call_tools(tool_calls) #工具输出
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 521, in call_tools
    msg = tool_fn.invoke(tool_call)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\base.py", line 610, in invoke
    return self.run(tool_input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\base.py", line 895, in run
    raise error_to_raise
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\tools\base.py", line 864, in run
    response = context.run(self._run, *tool_args, **tool_kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\tools\ddg_search\tool.py", line 112, in _run
    raw_results = self.api_wrapper.results(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\utilities\duckduckgo_search.py", line 146, in results
    for r in self._ddgs_text(query, max_results=max_results)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\utilities\duckduckgo_search.py", line 64, in _ddgs_text
    ddgs_gen = ddgs.text(
               ^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\duckduckgo_search\duckduckgo_search.py", line 185, in text
    raise DuckDuckGoSearchException(err)
duckduckgo_search.exceptions.DuckDuckGoSearchException: https://lite.duckduckgo.com/lite/ 202 Ratelimit
-chat_qa_chain_self_answer
2025-10-08 01:14:19,706 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\parsers\pdf.py", line 954, in _lazy_parse
    import pymupdf
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'pymupdf'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 652, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 696, in chat_answer
    new_docs=self.get_docs(upload_files)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 668, in get_docs
    doc = loader[1].load()
          ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\pdf.py", line 853, in load
    return list(self._lazy_load(**kwargs))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\pdf.py", line 850, in _lazy_load
    yield from parser._lazy_parse(blob, text_kwargs=kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\parsers\pdf.py", line 991, in _lazy_parse
    raise ImportError(
ImportError: pymupdf package not found, please install it with `pip install pymupdf`
-chat_qa_chain_self_answer
2025-10-08 01:22:25,768 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\retrievers\bm25.py", line 55, in from_texts
    from rank_bm25 import BM25Okapi
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'rank_bm25'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 650, in answer
    self.get_retriever(**kwargs)
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 213, in get_retriever
    self.bm25_retriever = BM25Retriever.from_documents(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\retrievers\bm25.py", line 102, in from_documents
    return cls.from_texts(
           ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\retrievers\bm25.py", line 57, in from_texts
    raise ImportError(
ImportError: Could not import rank_bm25, please install with `pip install rank_bm25`.
-chat_qa_chain_self_answer
2025-10-08 01:26:30,519 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 203, in add_files
    vectordb.add_documents(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\vectorstores\base.py", line 279, in add_documents
    return self.add_texts(texts, metadatas, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_chroma\vectorstores.py", line 578, in add_texts
    self._collection.upsert(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\Collection.py", line 442, in upsert
    upsert_request = self._validate_and_prepare_upsert_request(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 95, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 407, in _validate_and_prepare_upsert_request
    upsert_records = normalize_insert_record_set(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 330, in normalize_insert_record_set
    base_record_set = normalize_base_record_set(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 307, in normalize_base_record_set
    embeddings=normalize_embeddings(embeddings),
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 210, in normalize_embeddings
    raise ValueError(
ValueError: Expected Embeddings to be non-empty list or numpy array, got [] in upsert.
-create_db_info
2025-10-08 01:26:42,526 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 203, in add_files
    vectordb.add_documents(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\vectorstores\base.py", line 279, in add_documents
    return self.add_texts(texts, metadatas, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_chroma\vectorstores.py", line 578, in add_texts
    self._collection.upsert(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\Collection.py", line 442, in upsert
    upsert_request = self._validate_and_prepare_upsert_request(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 95, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 407, in _validate_and_prepare_upsert_request
    upsert_records = normalize_insert_record_set(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 330, in normalize_insert_record_set
    base_record_set = normalize_base_record_set(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 307, in normalize_base_record_set
    embeddings=normalize_embeddings(embeddings),
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 210, in normalize_embeddings
    raise ValueError(
ValueError: Expected Embeddings to be non-empty list or numpy array, got [] in upsert.
-create_db_info
2025-10-08 01:27:11,670 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 59, in __init__
    import unstructured  # noqa:F401
    ^^^^^^^^^^^^^^^^^^^
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'unstructured'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 195, in add_files
    = self.document_process(files, embedding_type, embeddings)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 230, in document_process
    file_loader(file, loaders)
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\utils\fileProcess.py", line 25, in file_loader
    loaders.append((file_name, UnstructuredFileLoader(file)))
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\_api\deprecation.py", line 226, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 213, in __init__
    super().__init__(mode=mode, **unstructured_kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 61, in __init__
    raise ImportError(
ImportError: unstructured package not found, please install it with `pip install unstructured`
-create_db_info
2025-10-08 01:28:53,790 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 195, in add_files
    = self.document_process(files, embedding_type, embeddings)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 245, in document_process
    subdocs: list[Document] = loader[1].load()
                              ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\document_loaders\base.py", line 43, in load
    return list(self.lazy_load())
           ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 107, in lazy_load
    elements = self._get_elements()
               ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 216, in _get_elements
    from unstructured.partition.auto import partition
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\auto.py", line 14, in <module>
    from unstructured.file_utils.filetype import (
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\file_utils\filetype.py", line 48, in <module>
    from unstructured.file_utils.encoding import detect_file_encoding, format_encoding_str
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\file_utils\encoding.py", line 3, in <module>
    from charset_normalizer import detect
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\charset_normalizer\__init__.py", line 24, in <module>
    from .api import from_bytes, from_fp, from_path, is_binary
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\charset_normalizer\api.py", line 5, in <module>
    from .cd import (
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\charset_normalizer\cd.py", line 14, in <module>
    from .md import is_suspiciously_successive_range
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "src\charset_normalizer\md.py", line 11, in <module>
ImportError: cannot import name 'is_cjk_uncommon' from 'charset_normalizer.utils' (D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\charset_normalizer\utils.py)
-create_db_info
2025-10-08 01:29:25,950 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 203, in add_files
    vectordb.add_documents(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\vectorstores\base.py", line 279, in add_documents
    return self.add_texts(texts, metadatas, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_chroma\vectorstores.py", line 578, in add_texts
    self._collection.upsert(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\Collection.py", line 442, in upsert
    upsert_request = self._validate_and_prepare_upsert_request(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 95, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 407, in _validate_and_prepare_upsert_request
    upsert_records = normalize_insert_record_set(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 330, in normalize_insert_record_set
    base_record_set = normalize_base_record_set(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 307, in normalize_base_record_set
    embeddings=normalize_embeddings(embeddings),
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 210, in normalize_embeddings
    raise ValueError(
ValueError: Expected Embeddings to be non-empty list or numpy array, got [] in upsert.
-create_db_info
2025-10-08 01:30:37,915 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 203, in add_files
    vectordb.add_documents(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\vectorstores\base.py", line 279, in add_documents
    return self.add_texts(texts, metadatas, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_chroma\vectorstores.py", line 578, in add_texts
    self._collection.upsert(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\Collection.py", line 442, in upsert
    upsert_request = self._validate_and_prepare_upsert_request(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 95, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 407, in _validate_and_prepare_upsert_request
    upsert_records = normalize_insert_record_set(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 330, in normalize_insert_record_set
    base_record_set = normalize_base_record_set(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 307, in normalize_base_record_set
    embeddings=normalize_embeddings(embeddings),
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 210, in normalize_embeddings
    raise ValueError(
ValueError: Expected Embeddings to be non-empty list or numpy array, got [] in upsert.
-create_db_info
2025-10-08 01:31:59,348 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 203, in add_files
    vectordb.add_documents(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\vectorstores\base.py", line 279, in add_documents
    return self.add_texts(texts, metadatas, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_chroma\vectorstores.py", line 578, in add_texts
    self._collection.upsert(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\Collection.py", line 442, in upsert
    upsert_request = self._validate_and_prepare_upsert_request(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 95, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 407, in _validate_and_prepare_upsert_request
    upsert_records = normalize_insert_record_set(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 330, in normalize_insert_record_set
    base_record_set = normalize_base_record_set(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 307, in normalize_base_record_set
    embeddings=normalize_embeddings(embeddings),
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 210, in normalize_embeddings
    raise ValueError(
ValueError: Expected Embeddings to be non-empty list or numpy array, got [] in upsert.
-create_db_info
2025-10-08 01:32:01,574 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 203, in add_files
    vectordb.add_documents(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\vectorstores\base.py", line 279, in add_documents
    return self.add_texts(texts, metadatas, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_chroma\vectorstores.py", line 578, in add_texts
    self._collection.upsert(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\Collection.py", line 442, in upsert
    upsert_request = self._validate_and_prepare_upsert_request(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 95, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 407, in _validate_and_prepare_upsert_request
    upsert_records = normalize_insert_record_set(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 330, in normalize_insert_record_set
    base_record_set = normalize_base_record_set(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 307, in normalize_base_record_set
    embeddings=normalize_embeddings(embeddings),
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\chromadb\api\types.py", line 210, in normalize_embeddings
    raise ValueError(
ValueError: Expected Embeddings to be non-empty list or numpy array, got [] in upsert.
-create_db_info
2025-10-08 01:38:05,898 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 652, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 701, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 721, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  [Previous line repeated 1 more time]
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 340, in query_change2
    queries = llm_chain2.invoke(inputs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3244, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\prompts\base.py", line 214, in invoke
    return self._call_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2092, in _call_with_config
    context.run(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\prompts\base.py", line 187, in _format_prompt_with_error_handling
    inner_input_ = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\prompts\base.py", line 181, in _validate_input
    raise KeyError(
KeyError: "Input to ChatPromptTemplate is missing variables {'query'}.  Expected: ['query'] Received: ['input', 'chat_history', 'web_context', 'tool_result', 'context', 'rag_context']\nNote: if you intended {query} to be part of the string and not a variable, please escape it with double curly braces like: '{{query}}'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
-chat_qa_chain_self_answer
2025-10-08 01:38:36,297 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 652, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 701, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 721, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  [Previous line repeated 1 more time]
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 340, in query_change2
    queries = llm_chain2.invoke(inputs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3244, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\prompts\base.py", line 214, in invoke
    return self._call_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2092, in _call_with_config
    context.run(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\prompts\base.py", line 187, in _format_prompt_with_error_handling
    inner_input_ = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\prompts\base.py", line 181, in _validate_input
    raise KeyError(
KeyError: "Input to ChatPromptTemplate is missing variables {'query'}.  Expected: ['query'] Received: ['input', 'chat_history', 'web_context', 'tool_result', 'context', 'rag_context']\nNote: if you intended {query} to be part of the string and not a variable, please escape it with double curly braces like: '{{query}}'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
-chat_qa_chain_self_answer
2025-10-08 01:40:45,390 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 652, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 701, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 721, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  [Previous line repeated 1 more time]
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 340, in query_change2
    queries = llm_chain2.invoke(inputs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3244, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\prompts\base.py", line 214, in invoke
    return self._call_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2092, in _call_with_config
    context.run(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\prompts\base.py", line 187, in _format_prompt_with_error_handling
    inner_input_ = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\prompts\base.py", line 181, in _validate_input
    raise KeyError(
KeyError: "Input to ChatPromptTemplate is missing variables {'query'}.  Expected: ['query'] Received: ['input', 'chat_history', 'web_context', 'tool_result', 'context', 'rag_context']\nNote: if you intended {query} to be part of the string and not a variable, please escape it with double curly braces like: '{{query}}'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
-chat_qa_chain_self_answer
2025-10-08 01:43:08,761 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 652, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 701, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 721, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  [Previous line repeated 1 more time]
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 340, in query_change2
    queries = llm_chain2.invoke(inputs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3244, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\prompts\base.py", line 214, in invoke
    return self._call_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2092, in _call_with_config
    context.run(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\prompts\base.py", line 187, in _format_prompt_with_error_handling
    inner_input_ = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\prompts\base.py", line 181, in _validate_input
    raise KeyError(
KeyError: "Input to ChatPromptTemplate is missing variables {'query'}.  Expected: ['query'] Received: ['input', 'chat_history', 'web_context', 'tool_result', 'context', 'rag_context']\nNote: if you intended {query} to be part of the string and not a variable, please escape it with double curly braces like: '{{query}}'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
-chat_qa_chain_self_answer
2025-10-08 11:50:28,692 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 195, in add_files
    = self.document_process(files, embedding_type, embeddings)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 245, in document_process
    subdocs: list[Document] = loader[1].load()
                              ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\document_loaders\base.py", line 43, in load
    return list(self.lazy_load())
           ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 107, in lazy_load
    elements = self._get_elements()
               ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\word_document.py", line 116, in _get_elements
    from unstructured.file_utils.filetype import FileType, detect_filetype
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\file_utils\filetype.py", line 48, in <module>
    from unstructured.file_utils.encoding import detect_file_encoding, format_encoding_str
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\file_utils\encoding.py", line 3, in <module>
    from charset_normalizer import detect
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\charset_normalizer\__init__.py", line 24, in <module>
    from .api import from_bytes, from_fp, from_path, is_binary
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\charset_normalizer\api.py", line 5, in <module>
    from .cd import (
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\charset_normalizer\cd.py", line 14, in <module>
    from .md import is_suspiciously_successive_range
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "src\charset_normalizer\md.py", line 11, in <module>
ImportError: cannot import name 'is_cjk_uncommon' from 'charset_normalizer.utils' (D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\charset_normalizer\utils.py)
-create_db_info
2025-10-08 11:53:24,813 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 195, in add_files
    = self.document_process(files, embedding_type, embeddings)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 245, in document_process
    subdocs: list[Document] = loader[1].load()
                              ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\document_loaders\base.py", line 43, in load
    return list(self.lazy_load())
           ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 107, in lazy_load
    elements = self._get_elements()
               ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\markdown.py", line 94, in _get_elements
    from unstructured.partition.md import partition_md
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'unstructured.partition.md'
-create_db_info
2025-10-08 15:18:20,544 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 195, in add_files
    = self.document_process(files, embedding_type, embeddings)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 245, in document_process
    subdocs: list[Document] = loader[1].load()
                              ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\document_loaders\base.py", line 43, in load
    return list(self.lazy_load())
           ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 107, in lazy_load
    elements = self._get_elements()
               ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\markdown.py", line 94, in _get_elements
    from unstructured.partition.md import partition_md
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\md.py", line 6, in <module>
    import markdown
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'markdown'
-create_db_info
2025-10-08 15:18:36,719 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 195, in add_files
    = self.document_process(files, embedding_type, embeddings)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 245, in document_process
    subdocs: list[Document] = loader[1].load()
                              ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\document_loaders\base.py", line 43, in load
    return list(self.lazy_load())
           ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 107, in lazy_load
    elements = self._get_elements()
               ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\word_document.py", line 137, in _get_elements
    from unstructured.partition.docx import partition_docx
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\docx.py", line 13, in <module>
    import docx
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'docx'
-create_db_info
2025-10-08 15:24:18,181 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 195, in add_files
    = self.document_process(files, embedding_type, embeddings)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 245, in document_process
    subdocs: list[Document] = loader[1].load()
                              ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\document_loaders\base.py", line 43, in load
    return list(self.lazy_load())
           ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 107, in lazy_load
    elements = self._get_elements()
               ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\word_document.py", line 137, in _get_elements
    from unstructured.partition.docx import partition_docx
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\docx.py", line 13, in <module>
    import docx
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'docx'
-create_db_info
2025-10-08 15:24:55,992 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 195, in add_files
    = self.document_process(files, embedding_type, embeddings)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 245, in document_process
    subdocs: list[Document] = loader[1].load()
                              ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\document_loaders\base.py", line 43, in load
    return list(self.lazy_load())
           ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 107, in lazy_load
    elements = self._get_elements()
               ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\markdown.py", line 94, in _get_elements
    from unstructured.partition.md import partition_md
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\md.py", line 6, in <module>
    import markdown
  File "F:\PyCharm 2025.1.2\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'markdown'
-create_db_info
2025-10-08 15:29:13,517 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 195, in add_files
    = self.document_process(files, embedding_type, embeddings)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 245, in document_process
    subdocs: list[Document] = loader[1].load()
                              ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\document_loaders\base.py", line 43, in load
    return list(self.lazy_load())
           ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 107, in lazy_load
    elements = self._get_elements()
               ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\markdown.py", line 96, in _get_elements
    return partition_md(filename=self.file_path, **self.unstructured_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\md.py", line 104, in partition_md
    return partition_html(
           ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\common\metadata.py", line 162, in wrapper
    elements = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\chunking\dispatch.py", line 74, in wrapper
    elements = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\partition.py", line 95, in partition_html
    return list(_HtmlPartitioner.iter_elements(opts))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\partition.py", line 206, in iter_elements
    yield from cls(opts)._iter_elements()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\partition.py", line 224, in _iter_elements
    for e in elements_iter:
             ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\parser.py", line 361, in iter_elements
    yield from block_item.iter_elements()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\parser.py", line 356, in iter_elements
    yield from self._element_from_text_or_tail(self.text or "", q, self._ElementCls)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\parser.py", line 386, in _element_from_text_or_tail
    yield from element_accum.flush(ElementCls)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\parser.py", line 254, in flush
    ElementCls = derive_element_type_from_text(normalized_text)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\parser.py", line 914, in derive_element_type_from_text
    if is_possible_narrative_text(text):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\text_type.py", line 84, in is_possible_narrative_text
    if "eng" in languages and (sentence_count(text, 3) < 2) and (not contains_verb(text)):
                                                                     ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\text_type.py", line 186, in contains_verb
    pos_tags = pos_tag(text)
               ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\nlp\tokenize.py", line 71, in pos_tag
    parts_of_speech.extend(_pos_tag(tokens))
                           ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\__init__.py", line 168, in pos_tag
    tagger = _get_tagger(lang)
             ^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\__init__.py", line 110, in _get_tagger
    tagger = PerceptronTagger()
             ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\perceptron.py", line 180, in __init__
    self.load_from_json(lang, loc)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\perceptron.py", line 277, in load_from_json
    loc = find(f"taggers/averaged_perceptron_tagger_{lang}")
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93maveraged_perceptron_tagger_eng[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('averaged_perceptron_tagger_eng')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtaggers/averaged_perceptron_tagger_eng[0m

  Searched in:
    - 'C:\\Users\\87391/nltk_data'
    - 'D:\\Anaconda\\envs\\rag_assistant_release\\nltk_data'
    - 'D:\\Anaconda\\envs\\rag_assistant_release\\share\\nltk_data'
    - 'D:\\Anaconda\\envs\\rag_assistant_release\\lib\\nltk_data'
    - 'C:\\Users\\87391\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

-create_db_info
2025-10-08 15:29:33,636 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 195, in add_files
    = self.document_process(files, embedding_type, embeddings)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 245, in document_process
    subdocs: list[Document] = loader[1].load()
                              ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\document_loaders\base.py", line 43, in load
    return list(self.lazy_load())
           ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 107, in lazy_load
    elements = self._get_elements()
               ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\word_document.py", line 139, in _get_elements
    return partition_docx(filename=self.file_path, **self.unstructured_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\common\metadata.py", line 162, in wrapper
    elements = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\chunking\dispatch.py", line 74, in wrapper
    elements = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\docx.py", line 149, in partition_docx
    return list(elements)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\docx.py", line 380, in _iter_document_elements
    yield from self._iter_paragraph_elements(block_item)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\docx.py", line 604, in _iter_paragraph_elements
    yield from self._classify_paragraph_to_element(item)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\docx.py", line 441, in _classify_paragraph_to_element
    TextSubCls = self._parse_paragraph_text_for_element_type(paragraph)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\docx.py", line 914, in _parse_paragraph_text_for_element_type
    if is_possible_narrative_text(text):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\text_type.py", line 84, in is_possible_narrative_text
    if "eng" in languages and (sentence_count(text, 3) < 2) and (not contains_verb(text)):
                                                                     ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\text_type.py", line 186, in contains_verb
    pos_tags = pos_tag(text)
               ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\nlp\tokenize.py", line 71, in pos_tag
    parts_of_speech.extend(_pos_tag(tokens))
                           ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\__init__.py", line 168, in pos_tag
    tagger = _get_tagger(lang)
             ^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\__init__.py", line 110, in _get_tagger
    tagger = PerceptronTagger()
             ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\perceptron.py", line 180, in __init__
    self.load_from_json(lang, loc)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\perceptron.py", line 277, in load_from_json
    loc = find(f"taggers/averaged_perceptron_tagger_{lang}")
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93maveraged_perceptron_tagger_eng[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('averaged_perceptron_tagger_eng')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtaggers/averaged_perceptron_tagger_eng[0m

  Searched in:
    - 'C:\\Users\\87391/nltk_data'
    - 'D:\\Anaconda\\envs\\rag_assistant_release\\nltk_data'
    - 'D:\\Anaconda\\envs\\rag_assistant_release\\share\\nltk_data'
    - 'D:\\Anaconda\\envs\\rag_assistant_release\\lib\\nltk_data'
    - 'C:\\Users\\87391\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

-create_db_info
2025-10-08 15:33:31,347 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 195, in add_files
    = self.document_process(files, embedding_type, embeddings)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 245, in document_process
    subdocs: list[Document] = loader[1].load()
                              ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\document_loaders\base.py", line 43, in load
    return list(self.lazy_load())
           ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 107, in lazy_load
    elements = self._get_elements()
               ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\word_document.py", line 139, in _get_elements
    return partition_docx(filename=self.file_path, **self.unstructured_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\common\metadata.py", line 162, in wrapper
    elements = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\chunking\dispatch.py", line 74, in wrapper
    elements = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\docx.py", line 149, in partition_docx
    return list(elements)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\docx.py", line 380, in _iter_document_elements
    yield from self._iter_paragraph_elements(block_item)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\docx.py", line 604, in _iter_paragraph_elements
    yield from self._classify_paragraph_to_element(item)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\docx.py", line 441, in _classify_paragraph_to_element
    TextSubCls = self._parse_paragraph_text_for_element_type(paragraph)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\docx.py", line 914, in _parse_paragraph_text_for_element_type
    if is_possible_narrative_text(text):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\text_type.py", line 84, in is_possible_narrative_text
    if "eng" in languages and (sentence_count(text, 3) < 2) and (not contains_verb(text)):
                                                                     ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\text_type.py", line 186, in contains_verb
    pos_tags = pos_tag(text)
               ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\nlp\tokenize.py", line 71, in pos_tag
    parts_of_speech.extend(_pos_tag(tokens))
                           ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\__init__.py", line 168, in pos_tag
    tagger = _get_tagger(lang)
             ^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\__init__.py", line 110, in _get_tagger
    tagger = PerceptronTagger()
             ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\perceptron.py", line 180, in __init__
    self.load_from_json(lang, loc)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\perceptron.py", line 277, in load_from_json
    loc = find(f"taggers/averaged_perceptron_tagger_{lang}")
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93maveraged_perceptron_tagger_eng[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('averaged_perceptron_tagger_eng')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtaggers/averaged_perceptron_tagger_eng[0m

  Searched in:
    - 'C:\\Users\\87391/nltk_data'
    - 'D:\\Anaconda\\envs\\rag_assistant_release\\nltk_data'
    - 'D:\\Anaconda\\envs\\rag_assistant_release\\share\\nltk_data'
    - 'D:\\Anaconda\\envs\\rag_assistant_release\\lib\\nltk_data'
    - 'C:\\Users\\87391\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

-create_db_info
2025-10-08 15:33:41,254 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 128, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings), gr.update(choices=DB.files.get(embeddings, []),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 174, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 195, in add_files
    = self.document_process(files, embedding_type, embeddings)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 245, in document_process
    subdocs: list[Document] = loader[1].load()
                              ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\document_loaders\base.py", line 43, in load
    return list(self.lazy_load())
           ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 107, in lazy_load
    elements = self._get_elements()
               ^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\document_loaders\markdown.py", line 96, in _get_elements
    return partition_md(filename=self.file_path, **self.unstructured_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\md.py", line 104, in partition_md
    return partition_html(
           ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\common\metadata.py", line 162, in wrapper
    elements = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\chunking\dispatch.py", line 74, in wrapper
    elements = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\partition.py", line 95, in partition_html
    return list(_HtmlPartitioner.iter_elements(opts))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\partition.py", line 206, in iter_elements
    yield from cls(opts)._iter_elements()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\partition.py", line 224, in _iter_elements
    for e in elements_iter:
             ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\parser.py", line 361, in iter_elements
    yield from block_item.iter_elements()
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\parser.py", line 356, in iter_elements
    yield from self._element_from_text_or_tail(self.text or "", q, self._ElementCls)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\parser.py", line 386, in _element_from_text_or_tail
    yield from element_accum.flush(ElementCls)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\parser.py", line 254, in flush
    ElementCls = derive_element_type_from_text(normalized_text)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\html\parser.py", line 914, in derive_element_type_from_text
    if is_possible_narrative_text(text):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\text_type.py", line 84, in is_possible_narrative_text
    if "eng" in languages and (sentence_count(text, 3) < 2) and (not contains_verb(text)):
                                                                     ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\partition\text_type.py", line 186, in contains_verb
    pos_tags = pos_tag(text)
               ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\unstructured\nlp\tokenize.py", line 71, in pos_tag
    parts_of_speech.extend(_pos_tag(tokens))
                           ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\__init__.py", line 168, in pos_tag
    tagger = _get_tagger(lang)
             ^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\__init__.py", line 110, in _get_tagger
    tagger = PerceptronTagger()
             ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\perceptron.py", line 180, in __init__
    self.load_from_json(lang, loc)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\tag\perceptron.py", line 277, in load_from_json
    loc = find(f"taggers/averaged_perceptron_tagger_{lang}")
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\nltk\data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93maveraged_perceptron_tagger_eng[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('averaged_perceptron_tagger_eng')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtaggers/averaged_perceptron_tagger_eng[0m

  Searched in:
    - 'C:\\Users\\87391/nltk_data'
    - 'D:\\Anaconda\\envs\\rag_assistant_release\\nltk_data'
    - 'D:\\Anaconda\\envs\\rag_assistant_release\\share\\nltk_data'
    - 'D:\\Anaconda\\envs\\rag_assistant_release\\lib\\nltk_data'
    - 'C:\\Users\\87391\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

-create_db_info
2025-10-08 17:32:20,479 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 705, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 725, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 592, in _transform
    for chunk in for_passthrough:
                 ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5927, in transform
    yield from self.bound.transform(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 295, in retriever_chain
    compressed_docs = compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain\retrievers\document_compressors\base.py", line 40, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\utils\reranker.py", line 54, in compress_documents
    scores = self.model.score(text_pairs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\cross_encoders\huggingface.py", line 59, in score
    scores = self.client.predict(text_pairs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\sentence_transformers\cross_encoder\util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\sentence_transformers\cross_encoder\CrossEncoder.py", line 651, in predict
    model_predictions = self.model(**features, return_dict=True)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\utils\generic.py", line 969, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\models\qwen3\modeling_qwen3.py", line 831, in forward
    raise ValueError("Cannot handle batch sizes > 1 if no padding token is defined.")
ValueError: Cannot handle batch sizes > 1 if no padding token is defined.
-chat_qa_chain_self_answer
2025-10-09 17:53:24,885 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 650, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 699, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 719, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 592, in _transform
    for chunk in for_passthrough:
                 ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5927, in transform
    yield from self.bound.transform(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 289, in retriever_chain
    compressed_docs = compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain\retrievers\document_compressors\base.py", line 40, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\utils\reranker.py", line 54, in compress_documents
    scores = self.model.score(text_pairs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\cross_encoders\huggingface.py", line 59, in score
    scores = self.client.predict(text_pairs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\sentence_transformers\cross_encoder\util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\sentence_transformers\cross_encoder\CrossEncoder.py", line 651, in predict
    model_predictions = self.model(**features, return_dict=True)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\utils\generic.py", line 969, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\models\qwen3\modeling_qwen3.py", line 831, in forward
    raise ValueError("Cannot handle batch sizes > 1 if no padding token is defined.")
ValueError: Cannot handle batch sizes > 1 if no padding token is defined.
-chat_qa_chain_self_answer
2025-10-09 18:34:21,463 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 653, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 702, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 722, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 592, in _transform
    for chunk in for_passthrough:
                 ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5927, in transform
    yield from self.bound.transform(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 292, in retriever_chain
    compressed_docs = compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain\retrievers\document_compressors\base.py", line 40, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\utils\reranker.py", line 54, in compress_documents
    scores = self.model.score(text_pairs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\cross_encoders\huggingface.py", line 59, in score
    scores = self.client.predict(text_pairs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\sentence_transformers\cross_encoder\util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\sentence_transformers\cross_encoder\CrossEncoder.py", line 651, in predict
    model_predictions = self.model(**features, return_dict=True)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\utils\generic.py", line 969, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\models\qwen3\modeling_qwen3.py", line 831, in forward
    raise ValueError("Cannot handle batch sizes > 1 if no padding token is defined.")
ValueError: Cannot handle batch sizes > 1 if no padding token is defined.
-chat_qa_chain_self_answer
2025-10-09 19:09:14,446 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 660, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 709, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 729, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 436, in web_search
    results = ddgs.text(query, max_results=kwargs["max_results"])
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\duckduckgo_search\duckduckgo_search.py", line 185, in text
    raise DuckDuckGoSearchException(err)
duckduckgo_search.exceptions.DuckDuckGoSearchException: https://lite.duckduckgo.com/lite/ 202 Ratelimit
-chat_qa_chain_self_answer
2025-10-09 19:09:33,725 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 658, in answer
    self.get_retriever(**kwargs)
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 231, in get_retriever
    self.reranker = CrossEncoderReranker2(model=self.rank_model, top_n=top_n,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\utils\reranker.py", line 30, in __init__
    super().__init__(**kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\pydantic\main.py", line 250, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for CrossEncoderReranker2
model
  Input should be an instance of BaseCrossEncoder [type=is_instance_of, input_value=CrossEncoder(
  (model): ...ivation_fn): Sigmoid()
), input_type=CrossEncoder]
    For further information visit https://errors.pydantic.dev/2.12/v/is_instance_of
-chat_qa_chain_self_answer
2025-10-09 19:27:15,331 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 94, in chat_qa_chain_self_answer
    for info,answer in output_stream:
                       ^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 662, in answer
    for info, answer in chat_answer:
                        ^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 711, in chat_answer
    for info, answer in self.stream(question, chat_chain,  chain_config, document_variable_names,
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 731, in stream
    for chunk in chat_chain.stream(chain_config):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
                  ^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\branch.py", line 350, in stream
    for chunk in runnable.stream(
                 ^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 592, in _transform
    for chunk in for_passthrough:
                 ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\utils\iter.py", line 70, in tee_peer
    item = next(iterator)
           ^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\Anaconda\envs\rag_assistant_release\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5927, in transform
    yield from self.bound.transform(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5129, in transform
    yield from self._transform_stream_with_config(
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\base.py", line 5096, in _transform
    output = call_func_with_variable_args(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 301, in retriever_chain
    compressed_docs = compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain\retrievers\document_compressors\base.py", line 40, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\BaiduSyncdisk\ntebook\Rag_Assistant\project\utils\reranker.py", line 54, in compress_documents
    scores = self.model.score(text_pairs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\langchain_community\cross_encoders\huggingface.py", line 59, in score
    scores = self.client.predict(text_pairs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\sentence_transformers\cross_encoder\util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\sentence_transformers\cross_encoder\CrossEncoder.py", line 651, in predict
    model_predictions = self.model(**features, return_dict=True)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\utils\generic.py", line 969, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\rag_assistant_release\Lib\site-packages\transformers\models\qwen3\modeling_qwen3.py", line 831, in forward
    raise ValueError("Cannot handle batch sizes > 1 if no padding token is defined.")
ValueError: Cannot handle batch sizes > 1 if no padding token is defined.
-chat_qa_chain_self_answer
2025-10-29 02:26:48,145 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\serve\run_rag_assistant.py", line 180, in create_db_info
    return DB.create_db_info(files, embedding_type, embeddings, embedding_dir
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 186, in create_db_info
    new_files, exist_files = self.add_files(files, embedding_type, embeddings, embedding_dir)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 208, in add_files
    = self.document_process(files, embedding_type, embeddings, embedding_model_dir)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\database\create_db.py", line 257, in document_process
    subdocs: list[Document] = loader[1].load()
                              ^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\document_loaders\base.py", line 43, in load
    return list(self.lazy_load())
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_community\document_loaders\unstructured.py", line 107, in lazy_load
    elements = self._get_elements()
               ^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_community\document_loaders\word_document.py", line 139, in _get_elements
    return partition_docx(filename=self.file_path, **self.unstructured_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\unstructured\partition\common\metadata.py", line 162, in wrapper
    elements = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\unstructured\chunking\dispatch.py", line 74, in wrapper
    elements = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\unstructured\partition\docx.py", line 138, in partition_docx
    opts = DocxPartitionerOptions.load(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\unstructured\partition\docx.py", line 186, in load
    return cls(**kwargs)._validate()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\unstructured\partition\docx.py", line 327, in _validate
    raise ValueError(f"not a ZIP archive (so not a DOCX file): {repr(self._file_path)}")
ValueError: not a ZIP archive (so not a DOCX file): 'C:\\Users\\Xufei Chen\\AppData\\Local\\Temp\\gradio\\d328c2cc291b7ad44f2ca76c77a8934fb629f8142964b842ba4e60035e00e31a\\新建 Microsoft Word 文档 2.docx'
-create_db_info
2025-10-29 14:08:59,500 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\httpcore\_sync\http11.py", line 213, in _receive_event
    with map_exceptions({h11.RemoteProtocolError: RemoteProtocolError}):
  File "C:\anaconda3\envs\rag_assistant\Lib\contextlib.py", line 155, in __exit__
    self.gen.throw(value)
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 664, in answer
    for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 718, in chat_answer
    for info, answer in self.stream( chat_chain,  chain_config, document_variable_names,
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 736, in stream
    for chunk in chat_chain.stream(chain_config):
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\passthrough.py", line 604, in _transform
    for chunk in map_output:
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_deepseek\chat_models.py", line 298, in _stream
    yield from super()._stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1092, in _stream
    for chunk in response:
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_streaming.py", line 46, in __iter__
    for item in self._iterator:
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_streaming.py", line 58, in __stream__
    for sse in iterator:
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_streaming.py", line 50, in _iter_events
    yield from self._decoder.iter_bytes(self.response.iter_bytes())
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_streaming.py", line 280, in iter_bytes
    for chunk in self._iter_chunks(iterator):
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_streaming.py", line 291, in _iter_chunks
    for chunk in iterator:
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\httpx\_transports\default.py", line 126, in __iter__
    with map_httpcore_exceptions():
  File "C:\anaconda3\envs\rag_assistant\Lib\contextlib.py", line 155, in __exit__
    self.gen.throw(value)
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)
-chat_qa_chain_self_answer
2025-10-29 14:37:13,583 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 105, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
                  ^^^^^^^^^^^^
AttributeError: 'RefineChain' object has no attribute 'stream'. Did you mean: 'astream'?
-chat_qa_chain_self_answer
2025-10-29 14:43:08,828 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 105, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\RefineChain.py", line 65, in stream
    for step in self.refine_chain.stream(input_dict, stream_mode="values"):
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\main.py", line 2657, in stream
    for _ in runner.tick(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 162, in tick
    run_with_retry(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 334, in invoke
    raise TypeError(
TypeError: No synchronous function provided to "generate_initial_summary".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
During task with name 'generate_initial_summary' and id 'a4eaec63-3cb9-56a4-0c8d-104112b6ab34'
-chat_qa_chain_self_answer
2025-10-29 14:47:12,900 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
TypeError: 'async_generator' object is not iterable
-chat_qa_chain_self_answer
2025-10-29 14:52:36,412 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 108, in astream_summary
    answer= f"<b>{i}.{file_name}文档摘要：</b><br>"+answer
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~
TypeError: can only concatenate str (not "coroutine") to str
-chat_qa_chain_self_answer
2025-10-29 15:43:50,166 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 107, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 72, in stream
    for result in self.map_reduce_chain.stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\main.py", line 2657, in stream
    for _ in runner.tick(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 162, in tick
    run_with_retry(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 659, in invoke
    input = step.invoke(input, config)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\graph\_branch.py", line 168, in _route
    result = self.path.invoke(value, config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 394, in invoke
    ret = context.run(self.func, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 118, in map_summaries
    page_contents = [doc.page_content for doc in state["context"]]
                                                 ~~~~~^^^^^^^^^^^
KeyError: 'context'
During task with name '__start__' and id 'e0d3489c-52e2-db50-a311-030a91221a17'
-chat_qa_chain_self_answer
2025-10-29 15:53:49,775 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 107, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 72, in stream
    for result in self.map_reduce_chain.stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\main.py", line 2657, in stream
    for _ in runner.tick(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 162, in tick
    run_with_retry(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 659, in invoke
    input = step.invoke(input, config)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\graph\_branch.py", line 168, in _route
    result = self.path.invoke(value, config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 394, in invoke
    ret = context.run(self.func, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 118, in map_summaries
    page_contents = [doc.page_content for doc in state["content"]]
                                                 ~~~~~^^^^^^^^^^^
KeyError: 'content'
During task with name '__start__' and id 'e4a24648-9924-9430-3054-e1359703db99'
-chat_qa_chain_self_answer
2025-10-29 16:03:58,503 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 107, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 72, in stream
    for result in self.map_reduce_chain.stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\main.py", line 2657, in stream
    for _ in runner.tick(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 162, in tick
    run_with_retry(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 659, in invoke
    input = step.invoke(input, config)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\graph\_branch.py", line 168, in _route
    result = self.path.invoke(value, config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 394, in invoke
    ret = context.run(self.func, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 126, in map_summaries
    page_contents = [doc.page_content for doc in state["context"]]
                                                 ~~~~~^^^^^^^^^^^
KeyError: 'context'
During task with name '__start__' and id 'cbe18f6b-ca49-c72e-4061-efc7f3a2004f'
-chat_qa_chain_self_answer
2025-10-29 16:12:50,117 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 107, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 72, in stream
    for result in self.map_reduce_chain.stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\main.py", line 2657, in stream
    for _ in runner.tick(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 162, in tick
    run_with_retry(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 659, in invoke
    input = step.invoke(input, config)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\graph\_branch.py", line 168, in _route
    result = self.path.invoke(value, config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 394, in invoke
    ret = context.run(self.func, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 128, in map_summaries
    page_contents = [doc.page_content for doc in state["context"]]
                                                 ~~~~~^^^^^^^^^^^
KeyError: 'context'
During task with name '__start__' and id '5562b19e-4a55-41c7-ab94-232d03ac928d'
-chat_qa_chain_self_answer
2025-10-29 16:18:00,162 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 107, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 71, in stream
    new_dict["context"] = input_dict[self.document_variable_name]
                          ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 'context'
-chat_qa_chain_self_answer
2025-10-29 16:19:50,291 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 107, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 73, in stream
    for result in self.map_reduce_chain.stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\main.py", line 2657, in stream
    for _ in runner.tick(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 253, in tick
    _panic_or_proceed(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 511, in _panic_or_proceed
    raise exc
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_executor.py", line 81, in done
    task.result()
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 119, in generate_summary
    response = self.map_chain.invoke(new_state)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_deepseek\chat_models.py", line 323, in _generate
    return super()._generate(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1136, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 173, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_deepseek\chat_models.py", line 298, in _stream
    yield from super()._stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1087, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'code': '1214', 'message': 'messages 参数非法。请检查文档。'}}
During task with name 'generate_summary' and id '7f831ded-1cee-2220-cd1a-4c51bfa3bcc6'
-chat_qa_chain_self_answer
2025-10-29 16:34:08,176 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 646, in answer
    self.param_set(**kwargs)
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 169, in param_set
    self.summarizer = LCELBrowser(llm=self.llm,
                      ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 56, in __init__
    self._create_chains()
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 63, in _create_chains
    self.map_reduce_chain = create_map_reduce_chain(self.llm, self.token_max, self.map_prompt, self.reduce_prompt,
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 126, in create_map_reduce_chain
    return MapReduceChain(llm, token_max, map_prompt, reduce_prompt, document_variable_name=document_variable_name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: MapReduceChain.__init__() got an unexpected keyword argument 'document_variable_name'
-chat_qa_chain_self_answer
2025-10-29 16:38:27,251 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 646, in answer
    self.param_set(**kwargs)
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 169, in param_set
    self.summarizer = LCELBrowser(llm=self.llm,
                      ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 56, in __init__
    self._create_chains()
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 63, in _create_chains
    self.map_reduce_chain = create_map_reduce_chain(self.llm, self.token_max, self.map_prompt, self.reduce_prompt,
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 126, in create_map_reduce_chain
    return MapReduceChain(llm, token_max, map_prompt, reduce_prompt)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 54, in __init__
    _validate_prompt(self.document_variable_name, self.map_prompt)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'MapReduceChain' object has no attribute 'document_variable_name'
-chat_qa_chain_self_answer
2025-10-29 16:42:08,449 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 107, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 65, in stream
    new_dict["context"] = input_dict[self.document_variable_name]
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'MapReduceChain' object has no attribute 'document_variable_name'
-chat_qa_chain_self_answer
2025-10-29 16:46:44,542 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 107, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 67, in stream
    for result in self.map_reduce_chain.stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\main.py", line 2657, in stream
    for _ in runner.tick(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 253, in tick
    _panic_or_proceed(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 511, in _panic_or_proceed
    raise exc
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_executor.py", line 81, in done
    task.result()
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 111, in generate_summary
    response = self.map_chain.invoke(state)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3244, in invoke
    input_ = context.run(step.invoke, input_, config, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\prompts\base.py", line 214, in invoke
    return self._call_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2092, in _call_with_config
    context.run(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\config.py", line 430, in call_func_with_variable_args
    return func(input, **kwargs)  # type: ignore[call-arg]
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\prompts\base.py", line 187, in _format_prompt_with_error_handling
    inner_input_ = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\prompts\base.py", line 181, in _validate_input
    raise KeyError(
KeyError: "Input to ChatPromptTemplate is missing variables {'context'}.  Expected: ['context'] Received: ['summaries', 'content']\nNote: if you intended {context} to be part of the string and not a variable, please escape it with double curly braces like: '{{context}}'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
During task with name 'generate_summary' and id 'c814ab27-f372-3a13-7f16-a29c4b3bab9f'
-chat_qa_chain_self_answer
2025-10-29 16:54:47,616 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 107, in astream_summary
    i=i+1
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 67, in stream
    for result in self.map_reduce_chain.stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\main.py", line 2657, in stream
    for _ in runner.tick(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 253, in tick
    _panic_or_proceed(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 511, in _panic_or_proceed
    raise exc
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_executor.py", line 81, in done
    task.result()
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 111, in generate_summary
    response = self.map_chain.invoke(state)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_deepseek\chat_models.py", line 323, in _generate
    return super()._generate(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1136, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 173, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_deepseek\chat_models.py", line 298, in _stream
    yield from super()._stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1087, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'code': '1214', 'message': 'messages 参数非法。请检查文档。'}}
During task with name 'generate_summary' and id '89f716a6-77b3-cf41-f4bf-84b3c693027e'
-chat_qa_chain_self_answer
2025-10-29 17:07:41,533 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 105, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 67, in stream
    for result in self.map_reduce_chain.stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\main.py", line 2657, in stream
    for _ in runner.tick(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 253, in tick
    _panic_or_proceed(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 511, in _panic_or_proceed
    raise exc
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_executor.py", line 81, in done
    task.result()
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 111, in generate_summary
    response = self.map_chain.invoke(state["context"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_deepseek\chat_models.py", line 323, in _generate
    return super()._generate(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1136, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 173, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_deepseek\chat_models.py", line 298, in _stream
    yield from super()._stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1087, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'code': '1214', 'message': 'messages 参数非法。请检查文档。'}}
During task with name 'generate_summary' and id '582b257d-e634-2af9-7cb4-3c2cc38892e3'
-chat_qa_chain_self_answer
2025-10-29 17:32:34,281 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 105, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 69, in stream
    for result in self.map_reduce_chain.stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\main.py", line 2657, in stream
    for _ in runner.tick(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 253, in tick
    _panic_or_proceed(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 511, in _panic_or_proceed
    raise exc
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_executor.py", line 81, in done
    task.result()
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 113, in generate_summary
    response = self.map_chain.invoke({"context":state["content"],"chat_history":state["chat_history"]})
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_deepseek\chat_models.py", line 323, in _generate
    return super()._generate(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1136, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 173, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_deepseek\chat_models.py", line 298, in _stream
    yield from super()._stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1087, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'code': '1214', 'message': 'messages 参数非法。请检查文档。'}}
During task with name 'generate_summary' and id '4625fea0-40a4-81dd-6d50-2365e871b419'
-chat_qa_chain_self_answer
2025-10-29 17:45:46,619 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 105, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 69, in stream
    for result in self.map_reduce_chain.stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\main.py", line 2657, in stream
    for _ in runner.tick(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 253, in tick
    _panic_or_proceed(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 511, in _panic_or_proceed
    raise exc
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_executor.py", line 81, in done
    task.result()
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 113, in generate_summary
    response = self.map_chain.invoke({"context":state["content"],"chat_history":state["chat_history"]})
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_deepseek\chat_models.py", line 323, in _generate
    return super()._generate(
           ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1136, in _generate
    return generate_from_stream(stream_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 173, in generate_from_stream
    generation = next(stream, None)
                 ^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_deepseek\chat_models.py", line 298, in _stream
    yield from super()._stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1087, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'code': '1214', 'message': 'messages 参数非法。请检查文档。'}}
During task with name 'generate_summary' and id 'f103c94e-75d7-3e53-262c-76cf06cefca6'
-chat_qa_chain_self_answer
2025-10-29 17:46:08,968 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 105, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 5888, in stream
    yield from self.bound.stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\output_parsers\transform.py", line 74, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2335, in _transform_stream_with_config
    final_input: Optional[Input] = next(input_for_tracing, None)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_deepseek\chat_models.py", line 298, in _stream
    yield from super()._stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1087, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.PermissionDeniedError: Error code: 403 - {'error': {'message': '免费API限制模型输入token小于4096，如有更多需求，请访问 https://api.chatanywhere.tech/#/shop 购买付费API。The number of prompt tokens for free accounts is limited to 4096. If you have additional requirements, please visit https://api.chatanywhere.tech/#/shop to purchase a premium key.(当前请求使用的ApiKey: sk-Hsr****fpgt)【如果您遇到问题，欢迎加入QQ群咨询：1048463714】', 'type': 'chatanywhere_error', 'param': None, 'code': '403 FORBIDDEN'}}
-chat_qa_chain_self_answer
2025-10-29 18:22:41,165 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 105, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\RefineChain.py", line 61, in stream
    if summary := step.content.get("summary"):
                  ^^^^^^^^^^^^
AttributeError: 'tuple' object has no attribute 'content'
-chat_qa_chain_self_answer
2025-10-29 18:30:39,436 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 105, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\RefineChain.py", line 62, in stream
    yield step.content
          ^^^^^^^^^^^^
AttributeError: 'tuple' object has no attribute 'content'
-chat_qa_chain_self_answer
2025-10-29 18:49:36,676 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 115, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 69, in stream
    for chunk in self.map_reduce_chain.stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\main.py", line 2657, in stream
    for _ in runner.tick(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 253, in tick
    _panic_or_proceed(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 511, in _panic_or_proceed
    raise exc
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_executor.py", line 81, in done
    task.result()
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 114, in generate_summary
    response = self.map_chain.invoke({"context":state["content"],"chat_history":state["chat_history"]})
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1080, in _generate_with_cache
    for chunk in self._stream(messages, stop=stop, **kwargs):
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_deepseek\chat_models.py", line 298, in _stream
    yield from super()._stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1087, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'code': '1214', 'message': 'messages 参数非法。请检查文档。'}}
During task with name 'generate_summary' and id '46d2e404-6587-5dc6-9afb-b66bffd0eabb'
-chat_qa_chain_self_answer
2025-10-29 19:39:33,830 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 115, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL,"context_num":len(split_docs)}):
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: RefineChain.stream() missing 1 required positional argument: 'context_num'
-chat_qa_chain_self_answer
2025-10-29 19:45:24,752 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 656, in answer
    for info, answer in abstract_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 845, in abstract_answer
    for info, ans in self.summarizer.astream_summary(docs, []):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\File_Browse_Chain.py", line 115, in astream_summary
    for answer in chain.stream({"context": split_docs, "chat_history": chat_history_LCEL,"context_num":len(split_docs)}):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 69, in stream
    for chunk in self.map_reduce_chain.stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\main.py", line 2657, in stream
    for _ in runner.tick(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 253, in tick
    _panic_or_proceed(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_runner.py", line 511, in _panic_or_proceed
    raise exc
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_executor.py", line 81, in done
    task.result()
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\MapReduceChain.py", line 117, in generate_summary
    response = self.map_chain.invoke({"context":state["content"],"chat_history":state["chat_history"]})
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3246, in invoke
    input_ = context.run(step.invoke, input_, config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1080, in _generate_with_cache
    for chunk in self._stream(messages, stop=stop, **kwargs):
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_deepseek\chat_models.py", line 298, in _stream
    yield from super()._stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1087, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'code': '1214', 'message': 'messages 参数非法。请检查文档。'}}
During task with name 'generate_summary' and id '9080c2ad-f60a-e2d5-528c-295c0f6a77b7'
-chat_qa_chain_self_answer
2025-10-29 20:05:46,026 - root - ERROR - chat_process发生错误：
Traceback (most recent call last):
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\Agent\agent.py", line 108, in chat_qa_chain_self_answer
    for info,answer in output_stream:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 664, in answer
    for info, answer in chat_answer:
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 718, in chat_answer
    for info, answer in self.stream( chat_chain,  chain_config, document_variable_names,
  File "C:\Users\Xufei Chen\Desktop\BaiduSyncdisk\ntebook\Rag_Assistant\project\qa_chain\Chat_QA_chain_self.py", line 736, in stream
    for chunk in chat_chain.stream(chain_config):
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\passthrough.py", line 614, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\passthrough.py", line 603, in _transform
    yield cast("dict[str, Any]", first_map_chunk_future.result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 4119, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 4103, in _transform
    chunk = AddableDict({step_name: future.result()})
                                    ^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\anaconda3\envs\rag_assistant\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_deepseek\chat_models.py", line 298, in _stream
    yield from super()._stream(
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\langchain_openai\chat_models\base.py", line 1087, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\anaconda3\envs\rag_assistant\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': '1113', 'message': '余额不足或无可用资源包,请充值。'}}
-chat_qa_chain_self_answer
